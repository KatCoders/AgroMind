import os
import tempfile
import streamlit as st
from st_audiorec import st_audiorec
import requests
from gtts import gTTS
import io
from datetime import datetime
import logging
import time

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import with error handling
try:
    from voice_pipeline import *
except ImportError:
    st.error("‚ùå voice_pipeline module not found!")
    get_llm_response = None
    chain = None

# --- üîë Keys ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (Streamlit Cloud Compatible) ---
try:
    GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "").strip()
except (FileNotFoundError, KeyError):
    GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()


# ===== CONFIGURATION =====
MAX_AUDIO_SIZE_KB = 1024
MIN_AUDIO_SIZE_KB = 5
MAX_TTS_CHARS = 3000
CACHE_TTL = 300

# ===== CUSTOM CSS FOR BETTER UI =====
def load_custom_css():
    """Enhanced UI with custom CSS"""
    st.markdown("""
    <style>
        /* Main container styling */
        .main {
            padding: 1rem;
        }
        
        /* Card-like containers */
        .stAlert {
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* Button styling */
        .stButton>button {
            border-radius: 8px;
            font-weight: 600;
            transition: all 0.3s ease;
        }
        
        .stButton>button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        /* Recording indicator */
        .recording-pulse {
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        
        /* Chat message styling */
        .chat-message {
            padding: 1rem;
            border-radius: 10px;
            margin: 0.5rem 0;
            animation: fadeIn 0.3s ease;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .user-message {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            margin-left: 20%;
        }
        
        .ai-message {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            margin-right: 20%;
        }
        
        /* Stats cards */
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1rem;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        .stat-number {
            font-size: 2rem;
            font-weight: bold;
        }
        
        .stat-label {
            font-size: 0.9rem;
            opacity: 0.9;
        }
        
        /* Progress bar */
        .stProgress > div > div {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        }
        
        /* Expander styling */
        .streamlit-expanderHeader {
            background-color: #f0f2f6;
            border-radius: 8px;
            font-weight: 600;
        }
        
        /* Audio player */
        audio {
            width: 100%;
            border-radius: 8px;
        }
        
        /* Language selector */
        .stSelectbox {
            border-radius: 8px;
        }
        
        /* Footer */
        .footer {
            text-align: center;
            padding: 2rem 0;
            color: #666;
            font-size: 0.9rem;
        }
        
        /* Loading animation */
        .loading-dots {
            display: inline-block;
        }
        
        .loading-dots span {
            animation: blink 1.4s infinite both;
        }
        
        .loading-dots span:nth-child(2) {
            animation-delay: 0.2s;
        }
        
        .loading-dots span:nth-child(3) {
            animation-delay: 0.4s;
        }
        
        @keyframes blink {
            0%, 80%, 100% { opacity: 0; }
            40% { opacity: 1; }
        }
        
        /* Tooltip */
        .tooltip {
            position: relative;
            display: inline-block;
        }
        
        /* Hide Streamlit branding for cleaner look */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .user-message, .ai-message {
                margin-left: 5%;
                margin-right: 5%;
            }
            
            .stat-number {
                font-size: 1.5rem;
            }
        }
    </style>
    """, unsafe_allow_html=True)


@st.cache_data(ttl=CACHE_TTL)
def get_supported_languages():
    """‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§≠‡§æ‡§∑‡§æ‡§è‡§Ç (cached)"""
    return {
        "hi": "üáÆüá≥ ‡§π‡§ø‡§Ç‡§¶‡•Ä",
        "en": "üá¨üáß English",
        "mr": "üáÆüá≥ ‡§Æ‡§∞‡§æ‡§†‡•Ä",
        "gu": "üáÆüá≥ ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä",
        "ta": "üáÆüá≥ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç",
        "te": "üáÆüá≥ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å",
        "bn": "üáÆüá≥ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ",
        "pa": "üáÆüá≥ ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä"
    }


def cleanup_temp_files(*file_paths):
    """‡§Ö‡§∏‡•ç‡§•‡§æ‡§à ‡§´‡§æ‡§á‡§≤‡•á‡§Ç ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç"""
    for fp in file_paths:
        try:
            if fp and os.path.exists(fp):
                os.unlink(fp)
        except Exception:
            pass


def transcribe_audio(audio_path: str, language: str = "hi") -> tuple:
    """
    Groq Whisper API ‡§∏‡•á ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç
    
    Returns:
        tuple: (transcript_text, confidence_score)
    """
    if not GROQ_API_KEY:
        raise ValueError("GROQ_API_KEY ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!")
    
    url = "https://api.groq.com/openai/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}
    
    with open(audio_path, "rb") as f:
        files = {"file": (os.path.basename(audio_path), f, "audio/wav")}
        data = {
            "model": "whisper-large-v3",
            "language": language,
            "response_format": "verbose_json",
            "temperature": 0.0,
            "prompt": get_language_prompt(language)
        }
        resp = requests.post(url, headers=headers, data=data, files=files, timeout=90)
    
    resp.raise_for_status()
    result = resp.json()
    
    text = result.get("text", "").strip()
    
    # Calculate confidence
    confidence = 1.0
    if "segments" in result and result["segments"]:
        avg_no_speech = sum(s.get("no_speech_prob", 0) for s in result["segments"]) / len(result["segments"])
        confidence = 1.0 - avg_no_speech
    
    return text, confidence


def get_language_prompt(lang: str) -> str:
    """Language-specific prompts for better transcription"""
    prompts = {
        "hi": "‡§Ø‡§π ‡§è‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡•â‡§Ø‡§∏ ‡§®‡•ã‡§ü ‡§π‡•à‡•§ ‡§∏‡§π‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§",
        "en": "This is a clear English voice note with proper pronunciation.",
        "mr": "‡§π‡•á ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§≠‡§æ‡§∑‡•á‡§§‡•Ä‡§≤ ‡§Ü‡§µ‡§æ‡§ú ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§Ü‡§π‡•á‡•§",
        "gu": "‡™Ü ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä ‡™≠‡™æ‡™∑‡™æ‡™Æ‡™æ‡™Ç ‡™µ‡´â‡™á‡™∏ ‡™®‡´ã‡™Ç‡™ß ‡™õ‡´á.",
        "ta": "‡Æá‡Æ§‡ØÅ ‡Æ§‡ØÜ‡Æ≥‡Æø‡Æµ‡Ææ‡Æ© ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æï‡ØÅ‡Æ∞‡Æ≤‡Øç ‡Æï‡ØÅ‡Æ±‡Æø‡Æ™‡Øç‡Æ™‡ØÅ.",
        "te": "‡∞á‡∞¶‡∞ø ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Æ‡±à‡∞® ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞®‡±ã‡∞ü‡±ç.",
        "bn": "‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶®‡ßã‡¶ü‡•§",
        "pa": "‡®á‡®π ‡®á‡©±‡®ï ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä ‡®µ‡©å‡®á‡®∏ ‡®®‡©ã‡®ü ‡®π‡©à‡•§"
    }
    return prompts.get(lang, "")


def text_to_speech(text: str, lang: str = "hi") -> bytes:
    """‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡ßç‡¶ü ‡§ï‡•ã ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç (gTTS)"""
    if len(text) > MAX_TTS_CHARS:
        text = text[:MAX_TTS_CHARS] + "..."
    
    tts = gTTS(text=text, lang=lang, slow=False)
    audio_bytes = io.BytesIO()
    tts.write_to_fp(audio_bytes)
    audio_bytes.seek(0)
    
    return audio_bytes.getvalue()


def initialize_session_state():
    """Session state ‡§ï‡•ã initialize ‡§ï‡§∞‡•á‡§Ç"""
    defaults = {
        "audio_path": None,
        "transcript": "",
        "ai_response": "",
        "processing": False,
        "conversation_history": [],
        "chat_history": [],
        "audio_quality_tips_shown": False,
        "voice_enabled": True,
        "tts_system": None,
        "total_conversations": 0,
        "total_words_spoken": 0,
        "avg_response_time": 0,
        "last_language": "hi"
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value



def show_stats_dashboard():
    """Statistics dashboard"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class='stat-card'>
            <div class='stat-number'>{st.session_state.total_conversations}</div>
            <div class='stat-label'>‡§¨‡§æ‡§§‡§ö‡•Ä‡§§</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class='stat-card'>
            <div class='stat-number'>{st.session_state.total_words_spoken}</div>
            <div class='stat-label'>‡§∂‡§¨‡•ç‡§¶ ‡§¨‡•ã‡§≤‡•á</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        avg_time = st.session_state.avg_response_time
        st.markdown(f"""
        <div class='stat-card'>
            <div class='stat-number'>{avg_time:.1f}s</div>
            <div class='stat-label'>‡§î‡§∏‡§§ ‡§∏‡§Æ‡§Ø</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        languages = get_supported_languages()
        lang_display = languages.get(st.session_state.last_language, "üáÆüá≥ ‡§π‡§ø‡§Ç‡§¶‡•Ä")
        st.markdown(f"""
        <div class='stat-card'>
            <div class='stat-number'>{lang_display.split()[0]}</div>
            <div class='stat-label'>‡§≠‡§æ‡§∑‡§æ</div>
        </div>
        """, unsafe_allow_html=True)


def show_audio_quality_tips():
    """Audio quality tips with better UI"""
    if not st.session_state.audio_quality_tips_shown:
        with st.expander("üí° ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡§ø‡§™‡•ç‡§∏", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **‚úÖ ‡§ï‡§∞‡•á‡§Ç:**
                - üì± ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§∞‡§π‡•á‡§Ç (15-20 cm)
                - üîá ‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π ‡§ö‡•Å‡§®‡•á‡§Ç
                - üó£Ô∏è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§î‡§∞ ‡§ß‡•Ä‡§∞‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç
                - ‚è∏Ô∏è ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§õ‡•ã‡§ü‡§æ pause ‡§¶‡•á‡§Ç
                """)
            
            with col2:
                st.markdown("""
                **‚ùå ‡§® ‡§ï‡§∞‡•á‡§Ç:**
                - üö´ ‡§§‡•á‡§ú ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç ‡§® ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ‡§è‡§Ç
                - üö´ ‡§¨‡§π‡•Å‡§§ ‡§§‡•á‡§ú ‡§Ø‡§æ ‡§¨‡§π‡•Å‡§§ ‡§ß‡•Ä‡§∞‡•á ‡§® ‡§¨‡•ã‡§≤‡•á‡§Ç
                - üö´ ‡§∂‡•ã‡§∞ ‡§µ‡§æ‡§≤‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§® ‡§ï‡§∞‡•á‡§Ç
                - üö´ ‡§Æ‡§æ‡§á‡§ï ‡§ï‡•ã ‡§π‡§æ‡§• ‡§∏‡•á ‡§® ‡§¢‡§ï‡•á‡§Ç
                """)
            
            st.session_state.audio_quality_tips_shown = True


def display_chat_message(role: str, content: str, timestamp: str = None):
    """Display a chat message with styling"""
    if role == "user":
        st.markdown(f"""
        <div class='chat-message user-message'>
            <div style='display: flex; align-items: center; margin-bottom: 0.5rem;'>
                <span style='font-size: 1.5rem; margin-right: 0.5rem;'>üë§</span>
                <strong>‡§Ü‡§™</strong>
                {f"<span style='margin-left: auto; font-size: 0.8rem; opacity: 0.8;'>{timestamp}</span>" if timestamp else ""}
            </div>
            <div>{content}</div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class='chat-message ai-message'>
            <div style='display: flex; align-items: center; margin-bottom: 0.5rem;'>
                <span style='font-size: 1.5rem; margin-right: 0.5rem;'>ü§ñ</span>
                <strong>AI ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü</strong>
                {f"<span style='margin-left: auto; font-size: 0.8rem; opacity: 0.8;'>{timestamp}</span>" if timestamp else ""}
            </div>
            <div>{content}</div>
        </div>
        """, unsafe_allow_html=True)


def voice_assistant_feature():
    """
    Ultra-Optimized Voice Assistant for Streamlit Cloud
    - Instant UI feedback
    - Streaming responses
    - Non-blocking operations
    - Better UX for slow networks
    """
 
    initialize_session_state()

    # ===== API VALIDATION =====
    if not GROQ_API_KEY:
        st.error("‚ùå **GROQ_API_KEY ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!**")
        with st.expander("üîß Setup Instructions", expanded=True):
            st.markdown("""
            **Streamlit Cloud ‡§™‡§∞ setup:**
            1. App settings ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§è‡§Ç ‚öôÔ∏è
            2. Secrets ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§è‡§Ç üîê
            3. Add ‡§ï‡§∞‡•á‡§Ç:
            ```toml
            GROQ_API_KEY = "your_key_here"
            ```
            4. Save ‡§î‡§∞ redeploy ‡§ï‡§∞‡•á‡§Ç üöÄ
            
            **‡§Ø‡§æ Local ‡§Æ‡•á‡§Ç:**
            ```bash
            export GROQ_API_KEY="your_key_here"
            ```
            """)
        return

  

    # ===== HEADER WITH STATS =====
    st.markdown("### üéôÔ∏è Voice Assistant")
    st.caption("‡§¨‡•ã‡§≤‡•ã, ‡§∏‡•Å‡§®‡•ã, ‡§∏‡§Æ‡§ù‡•ã - AI ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç")
    st.markdown("<br>", unsafe_allow_html=True)
    
    show_stats_dashboard()
    st.markdown("<br>", unsafe_allow_html=True)

    # ===== TABS =====
    tab1, tab2, tab3 = st.tabs(["üéôÔ∏è ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç", "üí¨ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§", "‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏"])

    # ===== TAB 1: RECORDING =====
    with tab1:
        # Tips toggle
        col_header, col_tips_btn = st.columns([3, 1])
        with col_header:
            st.markdown("#### üé§ ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç")
        with col_tips_btn:
            if st.button("üí° Tips", use_container_width=True, key="tips_toggle"):
                st.session_state.audio_quality_tips_shown = not st.session_state.get("audio_quality_tips_shown", False)

        show_audio_quality_tips()

        # Language selector
        st.markdown("---")
        languages = get_supported_languages()
        
        col_lang, col_status = st.columns([2, 1])
        
        with col_lang:
            lang_keys = list(languages.keys())
            default_lang = st.session_state.get("last_language", "hi")
            try:
                default_index = lang_keys.index(default_lang) if default_lang in lang_keys else 0
            except Exception:
                default_index = 0
            
            selected_lang = st.selectbox(
                "üåê ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                options=lang_keys,
                format_func=lambda x: languages[x],
                key="language_selector",
                index=default_index
            )
            st.session_state.last_language = selected_lang
        
        with col_status:
            # Processing status indicator
            if st.session_state.get("processing", False):
                st.markdown("""
                <div style='background: #fff3cd; padding: 1rem; border-radius: 8px; text-align: center;'>
                    <div class='loading-dots'>
                        <span>‚öôÔ∏è</span>
                        <span>‚öôÔ∏è</span>
                        <span>‚öôÔ∏è</span>
                    </div>
                    <div style='font-size: 0.8rem; color: #856404; margin-top: 0.5rem;'>
                        ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó...
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown("""
                <div style='background: #d4edda; padding: 1rem; border-radius: 8px; text-align: center;'>
                    <div style='font-size: 1.5rem;'>‚úÖ</div>
                    <div style='font-size: 0.8rem; color: #155724;'>‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à</div>
                </div>
                """, unsafe_allow_html=True)

        # Audio recorder
        st.markdown("---")
        st.markdown("##### üî¥ ‡§Ö‡§≠‡•Ä ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç")
        st.caption("‡§®‡•Ä‡§ö‡•á Record ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç ‚Üí ‡§¨‡•ã‡§≤‡•á‡§Ç ‚Üí Stop ‡§¶‡§¨‡§æ‡§è‡§Ç")
        
        audio_bytes = st_audiorec()

        # ===== AUDIO PROCESSING LOGIC =====
        if audio_bytes:
            # Validate audio size
            audio_size_kb = len(audio_bytes) / 1024
            
            # Show audio info
            col_info1, col_info2, col_info3 = st.columns(3)
            with col_info1:
                st.metric("üìä Size", f"{audio_size_kb:.1f} KB")
            with col_info2:
                duration = audio_size_kb / 16  # Approximate duration (16KB/sec for WAV)
                st.metric("‚è±Ô∏è Duration", f"~{duration:.1f}s")
            with col_info3:
                quality = "üü¢ Good" if MIN_AUDIO_SIZE_KB < audio_size_kb < MAX_AUDIO_SIZE_KB else "üü° Check"
                st.metric("‚ú® Quality", quality)
            
            # Validation warnings
            if audio_size_kb < MIN_AUDIO_SIZE_KB:
                st.warning("‚ö†Ô∏è Audio ‡§¨‡§π‡•Å‡§§ ‡§õ‡•ã‡§ü‡•Ä ‡§π‡•à‡•§ ‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ 2-3 ‡§∏‡•á‡§ï‡§Ç‡§° ‡§§‡§ï ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§")
            elif audio_size_kb > MAX_AUDIO_SIZE_KB:
                st.warning("‚ö†Ô∏è Audio ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•Ä ‡§π‡•à‡•§ ‡§õ‡•ã‡§ü‡•á ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§")
            
            # Save to temp file (clean previous if exists)
            if st.session_state.get("audio_path"):
                cleanup_temp_files(st.session_state.audio_path)
            
            try:
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tfile:
                    tfile.write(audio_bytes)
                    st.session_state.audio_path = tfile.name
                    st.success(f"‚úÖ Audio saved successfully!")
            except Exception as e:
                st.error(f"‚ùå Audio save failed: {e}")
                st.session_state.audio_path = None

            # Action buttons
            st.markdown("---")
            st.markdown("##### üöÄ ‡§Ö‡§¨ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•á‡§Ç?")
            
            col_btn1, col_btn2, col_btn3 = st.columns(3)

            with col_btn1:
                process_btn = st.button(
                    "ü§ñ AI ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç",
                    use_container_width=True,
                    disabled=st.session_state.get("processing", False),
                    type="primary",
                    key="process_audio_btn"
                )

            with col_btn2:
                if st.button(
                    "üîÑ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°",
                    use_container_width=True,
                    disabled=st.session_state.get("processing", False),
                    key="re_record_btn"
                ):
                    cleanup_temp_files(st.session_state.audio_path)
                    st.session_state.audio_path = None
                    st.session_state.transcript = ""
                    st.session_state.ai_response = ""
                    st.rerun()

            with col_btn3:
                if st.button(
                    "üóëÔ∏è Cancel",
                    use_container_width=True,
                    disabled=st.session_state.get("processing", False),
                    key="cancel_btn"
                ):
                    cleanup_temp_files(st.session_state.audio_path)
                    st.session_state.audio_path = None
                    st.session_state.transcript = ""
                    st.session_state.ai_response = ""
                    st.rerun()

            # ===== PROCESSING HANDLER =====
            if process_btn and st.session_state.audio_path:
                st.session_state.processing = True
                
                # Create dedicated processing container
                process_container = st.container()
                
                with process_container:
                    st.markdown("---")
                    st.markdown("### üîÑ Processing Your Request")
                    
                    # Progress tracking
                    progress_bar = st.progress(0, text="‡§∂‡•Å‡§∞‡•Ç ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...")
                    status_placeholder = st.empty()
                    result_placeholder = st.empty()
                    
                    start_time = time.time()
                    
                    try:
                        # ===== STEP 1: TRANSCRIPTION =====
                        status_placeholder.info("üß† **Step 1/3:** ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...")
                        progress_bar.progress(10, text="Transcribing audio...")
                        
                        transcript = ""
                        confidence = 0.0
                        
                        try:
                            transcript, confidence = transcribe_audio_with_retry(
                                st.session_state.audio_path,
                                selected_lang
                            )
                            st.session_state.transcript = transcript
                            
                            progress_bar.progress(35, text="Transcription complete!")
                            
                            if not transcript:
                                status_placeholder.error("‚ùå ‡§ï‡•ã‡§à ‡§∂‡§¨‡•ç‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§")
                                st.session_state.processing = False
                                progress_bar.empty()
                                time.sleep(2)
                                st.rerun()
                                return
                            
                            # Show transcript with confidence
                            confidence_emoji = "üü¢" if confidence > 0.8 else "üü°" if confidence > 0.6 else "üî¥"
                            result_placeholder.success(f"""
                            ‚úÖ **‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ:**  
                            "{transcript}"
                            
                            {confidence_emoji} Confidence: {confidence*100:.1f}%
                            """)
                            
                            # Update stats
                            word_count = len(transcript.split())
                            st.session_state.total_words_spoken += word_count
                            
                        except requests.exceptions.Timeout:
                            status_placeholder.error("‚ùå ‡§∏‡§Æ‡§Ø ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§: ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ß‡•Ä‡§Æ‡§æ ‡§π‡•à‡•§ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§")
                            st.session_state.error_count += 1
                            st.session_state.processing = False
                            progress_bar.empty()
                            time.sleep(2)
                            st.rerun()
                            return
                        
                        except Exception as e:
                            status_placeholder.error(f"‚ùå Transcription Error: {str(e)}")
                            st.info("üí° Check: Internet connection, GROQ API key, Audio quality")
                            st.session_state.error_count += 1
                            st.session_state.last_error = str(e)
                            st.session_state.processing = False
                            progress_bar.empty()
                            time.sleep(2)
                            st.rerun()
                            return
                        
                        # ===== STEP 2: AI RESPONSE GENERATION =====
                        if transcript:
                            status_placeholder.info("üí¨ **Step 2/3:** AI ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à...")
                            progress_bar.progress(50, text="Generating AI response...")
                            
                            full_response = ""
                            response_placeholder = st.empty()
                            
                            try:
                                # Build context from recent conversations
                                context = []
                                for conv in st.session_state.conversation_history[-3:]:
                                    context.append(f"User: {conv['user']}\nAI: {conv['ai']}")
                                context_str = "\n\n".join(context) if context else ""
                                
                                # Create query
                                query_input = {
                                    "question": transcript,
                                    "context": context_str if context_str else None
                                }
                                
                                # Stream response with visual feedback
                                chunk_count = 0
                                for chunk in chain.stream(query_input):
                                    full_response += chunk
                                    chunk_count += 1
                                    
                                    # Update progress (50-75%)
                                    progress_pct = min(75, 50 + (chunk_count // 5))
                                    progress_bar.progress(progress_pct, text=f"Streaming response... ({len(full_response)} chars)")
                                    
                                    # Update UI every 3 chunks for smooth streaming
                                    if chunk_count % 3 == 0:
                                        response_placeholder.markdown(f"""
                                        **ü§ñ AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨:**
                                        
                                        {full_response}‚ñå
                                        """)
                                
                                # Final response
                                response_placeholder.markdown(f"""
                                **ü§ñ AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨:**
                                
                                {full_response}
                                """)
                                
                                st.session_state.ai_response = full_response
                                progress_bar.progress(75, text="Response generated!")
                                
                            except Exception as e:
                                error_msg = str(e)
                                status_placeholder.error(f"‚ùå AI Response Error: {error_msg}")
                                full_response = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§æ‡•§"
                                response_placeholder.warning(full_response)
                                logger.error(f"LLM generation error: {e}", exc_info=True)
                                st.session_state.error_count += 1
                            
                            # Save to conversation history
                            timestamp = datetime.now().strftime("%I:%M %p")
                            
                            st.session_state.chat_history.append({
                                "role": "user",
                                "content": transcript,
                                "timestamp": timestamp
                            })
                            
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": full_response,
                                "timestamp": timestamp
                            })
                            
                            st.session_state.conversation_history.append({
                                "user": transcript,
                                "ai": full_response,
                                "lang": selected_lang,
                                "timestamp": datetime.now().isoformat()
                            })
                            
                            # ===== STEP 3: TEXT-TO-SPEECH =====
                            if full_response and st.session_state.voice_enabled and "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç" not in full_response:
                                status_placeholder.info("üéô **Step 3/3:** ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...")
                                progress_bar.progress(85, text="Generating audio...")
                                
                                try:
                                    audio_bytes_tts = text_to_speech(full_response, selected_lang)
                                    
                                    if audio_bytes_tts:
                                        progress_bar.progress(100, text="‚úÖ ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü!")
                                        status_placeholder.success("üéâ ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!")
                                        
                                        # Audio player with better UI
                                        st.markdown("---")
                                        st.markdown("#### üîä ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•Å‡§®‡•á‡§Ç")
                                        st.audio(audio_bytes_tts, format="audio/mp3")
                                        
                                except Exception as e:
                                    status_placeholder.warning(f"‚ö†Ô∏è ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ‡§à ‡§ú‡§æ ‡§∏‡§ï‡•Ä: {str(e)}")
                                    logger.warning(f"TTS error: {e}")
                                    progress_bar.progress(100, text="‚úÖ Text response ready!")
                            else:
                                progress_bar.progress(100, text="‚úÖ ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü!")
                                status_placeholder.success("üéâ ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!")
                            
                            # Update statistics
                            end_time = time.time()
                            response_time = end_time - start_time
                            
                            st.session_state.total_conversations += 1
                            
                            # Calculate running average
                            n = st.session_state.total_conversations
                            old_avg = st.session_state.avg_response_time
                            st.session_state.avg_response_time = (old_avg * (n-1) + response_time) / n
                            
                            # Success metrics
                            st.markdown("---")
                            col_m1, col_m2, col_m3 = st.columns(3)
                            with col_m1:
                                st.metric("‚è±Ô∏è Response Time", f"{response_time:.1f}s")
                            with col_m2:
                                st.metric("üìù Words", word_count)
                            with col_m3:
                                st.metric("üéØ Confidence", f"{confidence*100:.0f}%")
                    
                    except Exception as e:
                        status_placeholder.error(f"‚ùå Unexpected Error: {str(e)}")
                        logger.error(f"Critical error in process_audio_query: {e}", exc_info=True)
                        st.session_state.error_count += 1
                        st.session_state.last_error = str(e)
                    
                    finally:
                        # Cleanup
                        cleanup_temp_files(st.session_state.audio_path)
                        st.session_state.audio_path = None
                        st.session_state.processing = False
                        
                        # Clear progress UI after short delay
                        time.sleep(2)
                        progress_bar.empty()
                        
                        # Show completion message
                        st.success("‚úÖ Ready for next question!")
                        st.info("üí° Scroll up to record again or check conversation history")
                        
                        # Auto-refresh after 3 seconds (OPTIMIZED: was 60!)
                        with st.spinner("Refreshing in 3 seconds..."):
                            time.sleep(3)
                        st.rerun()

        else:
            # No audio recorded yet - Show instructions
            st.markdown("---")
            st.markdown("""
            <div style='text-align: center; padding: 2.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-top: 1rem; color: white;'>
                <div style='font-size: 3rem; margin-bottom: 1rem;'>üé§</div>
                <h3 style='color: white; margin-bottom: 1.5rem;'>‡§ï‡•à‡§∏‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç?</h3>
                <div style='background: rgba(255,255,255,0.1); border-radius: 10px; padding: 1.5rem; backdrop-filter: blur(10px);'>
                    <ol style='text-align: left; display: inline-block; color: white; line-height: 2;'>
                        <li><strong>üî¥ Record</strong> ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç</li>
                        <li><strong>üó£Ô∏è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§Ü‡§µ‡§æ‡§ú</strong> ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡•ã‡§≤‡•á‡§Ç</li>
                        <li><strong>‚èπÔ∏è Stop</strong> ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç</li>
                        <li><strong>üöÄ "AI ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç"</strong> ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç</li>
                        <li><strong>ü§ñ AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨</strong> ‡§∏‡•Å‡§®‡•á‡§Ç ‡§î‡§∞ ‡§™‡§¢‡§º‡•á‡§Ç</li>
                    </ol>
                </div>
                <div style='margin-top: 1.5rem; padding: 1rem; background: rgba(255,255,255,0.15); border-radius: 8px;'>
                    <p style='margin: 0; font-size: 0.9rem;'>üí° <strong>Pro Tip:</strong> ‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç, ‡§∏‡§æ‡§´ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞‡§£ ‡§∞‡§ñ‡•á‡§Ç</p>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # Quick tips
            st.markdown("---")
            col_tip1, col_tip2, col_tip3 = st.columns(3)
            
            with col_tip1:
                st.markdown("""
                <div style='padding: 1rem; background: #e8f5e9; border-radius: 10px; text-align: center;'>
                    <div style='font-size: 2rem;'>üéØ</div>
                    <strong style='color: #2e7d32;'>‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¨‡•ã‡§≤‡•á‡§Ç</strong>
                    <p style='font-size: 0.8rem; color: #666; margin-top: 0.5rem;'>Clear pronunciation ‡§ï‡•á ‡§≤‡§ø‡§è</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_tip2:
                st.markdown("""
                <div style='padding: 1rem; background: #e3f2fd; border-radius: 10px; text-align: center;'>
                    <div style='font-size: 2rem;'>üîá</div>
                    <strong style='color: #1565c0;'>‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π</strong>
                    <p style='font-size: 0.8rem; color: #666; margin-top: 0.5rem;'>Background noise ‡§∏‡•á ‡§¨‡§ö‡•á‡§Ç</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_tip3:
                st.markdown("""
                <div style='padding: 1rem; background: #fff3e0; border-radius: 10px; text-align: center;'>
                    <div style='font-size: 2rem;'>‚è±Ô∏è</div>
                    <strong style='color: #e65100;'>2-10 ‡§∏‡•á‡§ï‡§Ç‡§°</strong>
                    <p style='font-size: 0.8rem; color: #666; margin-top: 0.5rem;'>Ideal recording length</p>
                </div>
                """, unsafe_allow_html=True)

    # ===== TAB 2: CONVERSATION HISTORY =====
    with tab2:
        show_conversation_history()

    # ===== TAB 3: SETTINGS =====
    with tab3:
        show_settings()

    # ===== FOOTER =====
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; padding: 2rem 0; color: #666;'>
        <p style='font-size: 1rem; margin-bottom: 0.5rem;'>
            <strong>2024 ¬© AgroMind</strong> ‚Ä¢ All rights reserved
        </p>
        <p style='font-size: 0.85rem; color: #999;'>
            Made with ‚ù§Ô∏è for seamless voice interaction
        </p>
        <p style='font-size: 0.75rem; color: #aaa; margin-top: 0.5rem;'>
            Powered by Groq AI ‚Ä¢ Whisper V3 ‚Ä¢ Google TTS
        </p>
    </div>
    """, unsafe_allow_html=True)



def process_audio_query(selected_lang: str):
    """Process audio query with enhanced UI feedback - Optimized for speed"""
    st.session_state.processing = True
    start_time = time.time()
    
    # Clear previous responses to avoid confusion
    st.session_state.transcript = ""
    st.session_state.ai_response = ""
    
    # Progress tracking with better UI
    progress_container = st.container()
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Step 1: Transcription
        status_text.markdown("### üß† ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...")
        progress_bar.progress(25)
        
        try:
            transcript, confidence = transcribe_audio(st.session_state.audio_path, selected_lang)
            st.session_state.transcript = transcript
            
            if not transcript:
                st.error("‚ùå ‡§ï‡•ã‡§à ‡§∂‡§¨‡•ç‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§")
                st.session_state.processing = False
                progress_bar.empty()
                status_text.empty()
                return
            
            # Show confidence
            confidence_emoji = "üü¢" if confidence > 0.8 else "üü°" if confidence > 0.6 else "üî¥"
            
            progress_bar.progress(50)
            st.success(f"‚úÖ **‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ:** {transcript}")
            st.caption(f"{confidence_emoji} Confidence: {confidence*100:.1f}%")
            
            # Update stats
            word_count = len(transcript.split())
            st.session_state.total_words_spoken += word_count
                
        except requests.exceptions.Timeout:
            st.error("‚ùå Timeout: Network slow ‡§π‡•à‡•§ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§")
            st.session_state.processing = False
            progress_bar.empty()
            status_text.empty()
            return
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")
            st.info("üí° Check your internet connection ‡§î‡§∞ GROQ API key")
            st.session_state.processing = False
            progress_bar.empty()
            status_text.empty()
            return
        
        # Step 2: Get AI Response
        if transcript:
            status_text.markdown("### üí¨ AI ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à...")
            progress_bar.progress(75)
            
            full_response = ""
            try:
                response_placeholder = st.empty()
                
                # Create a fresh query without conversation history to avoid context issues
                # This ensures each query is independent and faster
                query_input = {"question": transcript}
                
                # Stream response with timeout
                chunk_count = 0
                for chunk in chain.stream(query_input):
                    full_response += chunk
                    chunk_count += 1
                    
                    # Update UI every 3 chunks for better performance
                    if chunk_count % 3 == 0:
                        response_placeholder.markdown(f"**ü§ñ AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨:**\n\n{full_response}‚ñå")
                
                response_placeholder.markdown(f"**ü§ñ AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨:**\n\n{full_response}")
                st.session_state.ai_response = full_response
                    
            except Exception as e:
                error_msg = f"‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {str(e)}"
                st.error(f"‚ùå {error_msg}")
                full_response = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§æ‡•§"
                logger.error(f"LLM generation error: {e}")
            
            # Save to history
            timestamp = datetime.now().strftime("%I:%M %p")
            
            st.session_state.chat_history.append({
                "role": "user", 
                "content": transcript, 
                "timestamp": timestamp
            })
            
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": full_response, 
                "timestamp": timestamp
            })
            
            st.session_state.conversation_history.append({
                "user": transcript,
                "ai": full_response,
                "lang": selected_lang,
                "timestamp": datetime.now().isoformat()
            })
            
            # Step 3: Generate audio
            if full_response and "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç" not in full_response:
                status_text.markdown("### üéô ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...")
                progress_bar.progress(90)
                
                try:
                    # Use threading to speed up TTS generation
                    audio_bytes_tts = text_to_speech(full_response, selected_lang)
                    
                    if audio_bytes_tts:
                        progress_bar.progress(100)
                        status_text.markdown("### ‚úÖ ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü!")
                        st.audio(audio_bytes_tts, format="audio/mp3")
                        
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ‡§à ‡§ú‡§æ ‡§∏‡§ï‡•Ä")
                    logger.warning(f"TTS error: {e}")
            
            # Update stats
            end_time = time.time()
            response_time = end_time - start_time
            
            st.session_state.total_conversations += 1
            
            # Calculate running average
            n = st.session_state.total_conversations
            old_avg = st.session_state.avg_response_time
            st.session_state.avg_response_time = (old_avg * (n-1) + response_time) / n
            
            # Clear progress immediately for faster UX
            progress_bar.empty()
            status_text.empty()
        
        st.session_state.processing = False
        
        # Cleanup audio file immediately after processing
        cleanup_temp_files(st.session_state.audio_path)
        st.session_state.audio_path = None
        
        # Success message
        st.success(f"‚úÖ ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü! ({response_time:.1f} seconds)")
        
        # Auto-rerun to reset recording interface
        time.sleep(60)
        st.rerun()


def show_conversation_history():
    """Display conversation history with better UI"""
    st.markdown("### üí¨ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏")
    
    if not st.session_state.conversation_history:
        st.info("üì≠ ‡§Ö‡§≠‡•Ä ‡§§‡§ï ‡§ï‡•ã‡§à ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§®‡§π‡•Ä‡§Ç‡•§ Record ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§ï‡§∞ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç!")
        return
    
    # Filter options
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.caption(f"‡§ï‡•Å‡§≤ {len(st.session_state.conversation_history)} ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§")
    with col2:
        show_all = st.checkbox("‡§∏‡§≠‡•Ä ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç", value=False)
    with col3:
        if st.button("üóëÔ∏è ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç", use_container_width=True):
            st.session_state.conversation_history = []
            st.session_state.chat_history = []
            st.success("‚úÖ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§æ‡§´ ‡§π‡•ã ‡§ó‡§Ø‡§æ!")
            st.rerun()
    
    display_count = len(st.session_state.conversation_history) if show_all else min(10, len(st.session_state.conversation_history))
    
    # Display conversations
    for i, conv in enumerate(reversed(st.session_state.conversation_history[-display_count:])):
        with st.container():
            st.markdown(f"**#{len(st.session_state.conversation_history) - i}** ‚Ä¢ {conv.get('lang', 'hi').upper()}")
            
            # User message
            display_chat_message("user", conv['user'], 
                               datetime.fromisoformat(conv['timestamp']).strftime("%I:%M %p") if 'timestamp' in conv else None)
            
            # AI message  
            display_chat_message("assistant", conv['ai'],
                               datetime.fromisoformat(conv['timestamp']).strftime("%I:%M %p") if 'timestamp' in conv else None)
            
            if i < display_count - 1:
                st.markdown("<br>", unsafe_allow_html=True)


def show_settings():
    """Settings panel"""
    st.markdown("### ‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏")
    
    # Voice settings
    st.markdown("#### üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏")
    st.session_state.voice_enabled = st.toggle("‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•Å‡§®‡•á‡§Ç", value=st.session_state.voice_enabled)
    
    if st.session_state.voice_enabled:
        st.info("‚úÖ AI ‡§ï‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§®‡§æ‡§à ‡§¶‡•á‡§Ç‡§ó‡•á")
    else:
        st.warning("‚ö†Ô∏è ‡§ï‡•á‡§µ‡§≤ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ")
    
    st.markdown("---")
    
    # Performance settings
    st.markdown("#### ‚ö° Performance")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("‡§ï‡•Å‡§≤ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§", st.session_state.total_conversations)
        st.metric("‡§ï‡•Å‡§≤ ‡§∂‡§¨‡•ç‡§¶", st.session_state.total_words_spoken)
    
    with col2:
        st.metric("‡§î‡§∏‡§§ ‡§∏‡§Æ‡§Ø", f"{st.session_state.avg_response_time:.1f}s")
        st.metric("‡§≠‡§æ‡§∑‡§æ", get_supported_languages().get(st.session_state.last_language, "‡§π‡§ø‡§Ç‡§¶‡•Ä"))
    
    st.markdown("---")
    
    # Clear data
    st.markdown("#### üóëÔ∏è Data Management")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üîÑ Stats ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", use_container_width=True):
            st.session_state.total_conversations = 0
            st.session_state.total_words_spoken = 0
            st.session_state.avg_response_time = 0
            st.success("‚úÖ Stats ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§π‡•ã ‡§ó‡§è!")
            st.rerun()
    
    with col2:
        if st.button("üóëÔ∏è ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç", type="primary", use_container_width=True):
            # Clear everything
            st.session_state.conversation_history = []
            st.session_state.chat_history = []
            st.session_state.total_conversations = 0
            st.session_state.total_words_spoken = 0
            st.session_state.avg_response_time = 0
            cleanup_temp_files(st.session_state.audio_path)
            st.session_state.audio_path = None
            st.success("‚úÖ ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§∏‡§æ‡§´ ‡§π‡•ã ‡§ó‡§Ø‡§æ!")
            st.rerun()
    
    st.markdown("---")
    
    # System info
    st.markdown("#### ‚ÑπÔ∏è System Info")
    st.info(f"""
    **Model:** Whisper Large V3  
    **LLM:** Groq (via voice_pipeline)  
    **TTS:** Google Text-to-Speech  
    **Status:** ‚úÖ Connected
    """)


# Cleanup on session end
def cleanup_on_session_end():
    """Session end ‡§™‡§∞ cleanup"""
    try:
        if hasattr(st.session_state, 'audio_path') and st.session_state.audio_path:
            cleanup_temp_files(st.session_state.audio_path)
    except Exception:
        pass
