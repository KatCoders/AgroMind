import os
import tempfile
import streamlit as st
from st_audiorec import st_audiorec
import requests
from gtts import gTTS

# Import with error handling
try:
    from voice_pipeline import get_llm_response
except ImportError:
    st.error("‚ùå voice_pipeline module not found!")
    get_llm_response = None

# --- üîë Keys ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (Streamlit Cloud Compatible) ---
# Streamlit Cloud ‡§Æ‡•á‡§Ç secrets.toml ‡§∏‡•á ‡§™‡§¢‡§º‡•á‡§Ç, local ‡§Æ‡•á‡§Ç environment variable ‡§∏‡•á
try:
    GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "").strip()
except (FileNotFoundError, KeyError):
    GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()


@st.cache_data(ttl=300)
def get_supported_languages():
    """‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§≠‡§æ‡§∑‡§æ‡§è‡§Ç (cached)"""
    return {
        "hi": "üáÆüá≥ ‡§π‡§ø‡§Ç‡§¶‡•Ä",
        "en": "üá¨üáß English",
        "mr": "üáÆüá≥ ‡§Æ‡§∞‡§æ‡§†‡•Ä",
        "gu": "üáÆüá≥ ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä",
        "ta": "üáÆüá≥ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç",
        "te": "üáÆüá≥ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å"
    }


def cleanup_temp_files(*file_paths):
    """‡§Ö‡§∏‡•ç‡§•‡§æ‡§à ‡§´‡§æ‡§á‡§≤‡•á‡§Ç ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç"""
    for fp in file_paths:
        try:
            if fp and os.path.exists(fp):
                os.unlink(fp)
        except Exception:
            pass


def transcribe_audio(audio_path: str, language: str = "hi") -> str:
    """
    Groq Whisper API ‡§∏‡•á ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç
    
    Args:
        audio_path: ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§á‡§≤ ‡§ï‡§æ path
        language: ‡§≠‡§æ‡§∑‡§æ ‡§ï‡•ã‡§° (default: hi)
    
    Returns:
        ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü
    """
    if not GROQ_API_KEY:
        raise ValueError("GROQ_API_KEY ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!")
    
    url = "https://api.groq.com/openai/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}
    
    with open(audio_path, "rb") as f:
        files = {"file": (os.path.basename(audio_path), f, "audio/wav")}
        data = {
            "model": "whisper-large-v3-turbo",
            "language": language,
            "response_format": "text",
            "temperature": 0.0  # More deterministic
        }
        resp = requests.post(url, headers=headers, data=data, files=files, timeout=60)
    
    resp.raise_for_status()
    return resp.text.strip()


def text_to_speech(text: str, lang: str = "hi") -> str:
    """
    ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç (gTTS)
    
    Args:
        text: ‡§¨‡•ã‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü
        lang: ‡§≠‡§æ‡§∑‡§æ ‡§ï‡•ã‡§°
    
    Returns:
        ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§á‡§≤ ‡§ï‡§æ path
    """
    # Limit text length for TTS (gTTS has limits)
    max_chars = 5000
    if len(text) > max_chars:
        text = text[:max_chars] + "..."
    
    tts = gTTS(text=text, lang=lang, slow=False)
    tts_path = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False).name
    tts.save(tts_path)
    return tts_path


def initialize_session_state():
    """Session state ‡§ï‡•ã initialize ‡§ï‡§∞‡•á‡§Ç"""
    defaults = {
        "audio_path": None,
        "tts_path": None,
        "transcript": "",
        "ai_response": "",
        "processing": False,
        "conversation_history": []
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def voice_assistant_feature():
    """
    üéô Streamlit Cloud-friendly Voice Assistant
    - ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§Ü‡§µ‡§æ‡§ú‡§º
    - ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ (Whisper via Groq)
    - GPT ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨
    - ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§®‡•á (gTTS)
    """
    
    # Initialize session state
    initialize_session_state()
    
    # API key check ‡§ï‡§∞‡•á‡§Ç
    if not GROQ_API_KEY:
        st.error("‚ùå **GROQ_API_KEY ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!**")
        st.info("""
        **Streamlit Cloud ‡§™‡§∞ setup:**
        1. App settings ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§è‡§Ç
        2. Secrets ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§è‡§Ç
        3. Add ‡§ï‡§∞‡•á‡§Ç:
        ```toml
        GROQ_API_KEY = "your_key_here"
        ```
        """)
        return
    
    if get_llm_response is None:
        st.error("‚ùå voice_pipeline module ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à!")
        return
    
    # Header
    st.markdown("### üé§ Voice Assistant")
    
    # Language selector
    languages = get_supported_languages()
    col1, col2 = st.columns([3, 1])
    
    with col2:
        selected_lang = st.selectbox(
            "‡§≠‡§æ‡§∑‡§æ",
            options=list(languages.keys()),
            format_func=lambda x: languages[x],
            key="language_selector",
            label_visibility="collapsed"
        )
    
    with col1:
        st.caption(f"Selected: {languages[selected_lang]}")
    
    # --- üéô Audio Recording ---
    st.markdown("#### üéôÔ∏è ‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç")
    audio_bytes = st_audiorec()
    
    if audio_bytes:
        # Display recorded audio
        st.audio(audio_bytes, format="audio/wav")
        
        # Save to temporary file
        if st.session_state.audio_path:
            cleanup_temp_files(st.session_state.audio_path)
        
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tfile:
            tfile.write(audio_bytes)
            st.session_state.audio_path = tfile.name
        
        # Process button
        col_btn1, col_btn2 = st.columns([2, 1])
        
        with col_btn1:
            process_btn = st.button(
                "‚ñ∂ ‡§™‡•Ç‡§õ‡•á‡§Ç AI ‡§∏‡•á",
                type="primary",
                use_container_width=True,
                disabled=st.session_state.processing
            )
        
        with col_btn2:
            if st.button("üóëÔ∏è Clear", use_container_width=True):
                cleanup_temp_files(st.session_state.audio_path, st.session_state.tts_path)
                st.session_state.audio_path = None
                st.session_state.tts_path = None
                st.session_state.transcript = ""
                st.session_state.ai_response = ""
                st.rerun()
        
        if process_btn:
            st.session_state.processing = True
            transcript = ""
            
            # Step 1: Transcription
            with st.spinner("üß† ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                try:
                    transcript = transcribe_audio(st.session_state.audio_path, selected_lang)
                    st.session_state.transcript = transcript
                except requests.exceptions.Timeout:
                    st.error("‚ùå Timeout: API response ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§∞‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§")
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ùå API Error: {str(e)}")
                except Exception as e:
                    st.error(f"‚ùå ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§Ö‡§∏‡§´‡§≤: {str(e)}")
            
            # Step 2: Get AI Response
            if transcript:
                st.info(f"üìù **‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ:** {transcript}")
                
                with st.spinner("üí¨ AI ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à..."):
                    try:
                        response_text = get_llm_response(transcript)
                        st.session_state.ai_response = response_text
                        
                        # Save to conversation history
                        st.session_state.conversation_history.append({
                            "user": transcript,
                            "ai": response_text
                        })
                        
                    except Exception as e:
                        st.error(f"‚ùå AI Error: {str(e)}")
                        response_text = ""
                
                # Step 3: Text to Speech
                if response_text:
                    
                    
                    with st.spinner("üéô ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                        try:
                            # Cleanup old TTS file
                            if st.session_state.tts_path:
                                cleanup_temp_files(st.session_state.tts_path)
                            
                            st.session_state.tts_path = text_to_speech(response_text, selected_lang)
                            st.audio(st.session_state.tts_path, format="audio/mp3")
                            
                        except Exception as e:
                            st.error(f"‚ùå TTS Error: {str(e)}")
                            st.info("üí° Tip: ‡§Ü‡§™ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§ä‡§™‡§∞ ‡§™‡§¢‡§º ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§")
                else:
                    st.warning("‚ö† AI ‡§∏‡•á ‡§ï‡•ã‡§à ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§")
            else:
                st.warning("‚ö† ‡§ï‡•ã‡§à ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§")
            
            st.session_state.processing = False
    
    else:
        st.info("üé§ ‡§ä‡§™‡§∞ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§¨‡•ã‡§≤‡•á‡§Ç...")
    
    # Show conversation history
    if st.session_state.conversation_history:
        with st.expander("üìú ‡§™‡§ø‡§õ‡§≤‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§¶‡•á‡§ñ‡•á‡§Ç", expanded=False):
            for i, conv in enumerate(reversed(st.session_state.conversation_history[-5:])):
                st.markdown(f"**üë§ You:** {conv['user']}")
                st.markdown(f"**ü§ñ AI:** {conv['ai']}")
                if i < len(st.session_state.conversation_history) - 1:
                    st.divider()
    
    # Footer
    st.markdown("---")
    col_f1, col_f2 = st.columns([2, 1])
    with col_f1:
        st.caption("‚ú® Powered by Whisper + GPT + gTTS üöÄ")
    with col_f2:
        if st.button("üóë Clear All History"):
            st.session_state.conversation_history = []
            cleanup_temp_files(st.session_state.audio_path, st.session_state.tts_path)
            st.session_state.audio_path = None
            st.session_state.tts_path = None
            st.success("‚úÖ History cleared!")
            st.rerun()


# Cleanup function for temp files (best effort)
def cleanup_on_session_end():
    """Session end ‡§™‡§∞ cleanup (Streamlit Cloud friendly)"""
    try:
        if hasattr(st.session_state, 'audio_path'):
            cleanup_temp_files(st.session_state.audio_path)
        if hasattr(st.session_state, 'tts_path'):
            cleanup_temp_files(st.session_state.tts_path)
    except Exception:
        pass
