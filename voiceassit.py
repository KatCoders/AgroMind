import os
import tempfile
import streamlit as st
from st_audiorec import st_audiorec
from dotenv import load_dotenv
import requests
from gtts import gTTS
from voice_pipeline import get_llm_response  # тЬЕ рдЖрдкрдХреА LLM рдкрд╛рдЗрдкрд▓рд╛рдЗрди

# --- ЁЯФС Keys рд▓реЛрдб рдХрд░реЗрдВ ---
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()


def voice_assistant_feature():
    """
    ЁЯОЩ Fun рдФрд░ compact Voice Assistant feature
    - рд░рд┐рдХреЙрд░реНрдб рдЖрд╡рд╛рдЬрд╝
    - рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд╛рдЗрдм (Whisper via Groq)
    - GPT рд╕реЗ рдЬрд╡рд╛рдм
    - рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рд╕реБрдиреЗ (gTTS)
    """
    st.markdown("# ЁЯОЩ рдмреЛрд▓реЛ рдФрд░ рд╕реБрдиреЛ тАФ AI рд╡реЙрдЗрд╕ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ ЁЯЪА")
    st.markdown("ЁЯОд рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ тЖТ ЁЯза GPT рдЬрд╡рд╛рдм рджреЗрдЧрд╛ тЖТ ЁЯФК рд╕реБрдиреЗрдВ")

    # --- ЁЯОЩ Record your voice ---
    audio_bytes = st_audiorec()
    if audio_bytes:
        st.audio(audio_bytes, format="audio/wav")
        
        # рдЕрд╕реНрдерд╛рдИ рдлрд╛рдЗрд▓ рдореЗрдВ рд╕реЗрд╡
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tfile:
            tfile.write(audio_bytes)
            audio_path = tfile.name

        if st.button("тЦ╢ рдкреВрдЫреЗрдВ AI рд╕реЗ"):
            with st.spinner("ЁЯза рдЖрдкрдХреА рдЖрд╡рд╛рдЬрд╝ рдХреЛ рд╕рдордЭ рд░рд╣реЗ рд╣реИрдВ..."):
                transcript = ""
                try:
                    url = "https://api.groq.com/openai/v1/audio/transcriptions"
                    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}
                    with open(audio_path, "rb") as f:
                        files = {"file": (os.path.basename(audio_path), f, "audio/wav")}
                        data = {"model": "whisper-large-v3-turbo", "language": "hi", "response_format": "text"}
                        resp = requests.post(url, headers=headers, data=data, files=files, timeout=45)
                    resp.raise_for_status()
                    transcript = resp.text.strip()
                except Exception as e:
                    st.error(f"тЭМ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рдЕрд╕рдлрд▓: {e}")

            if transcript:
                st.info(f"ЁЯУЭ рдЖрдкрдиреЗ рдХрд╣рд╛: {transcript}")
                with st.spinner("ЁЯТм AI рдЬрд╡рд╛рдм рд╕реЛрдЪ рд░рд╣рд╛ рд╣реИ..."):
                    try:
                        response_text = get_llm_response(transcript)
                    except Exception as e:
                        st.error(f"тЭМ AI рдЬрд╡рд╛рдм рдирд╣реАрдВ рдорд┐рд▓рд╛: {e}")
                        response_text = ""

                if response_text:
                    st.success(f"ЁЯдЦ AI: {response_text}")
                    with st.spinner("ЁЯОЩ рдЬрд╡рд╛рдм рдХреЛ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рдмрджрд▓ рд░рд╣реЗ рд╣реИрдВ..."):
                        try:
                            tts = gTTS(text=response_text, lang="hi")
                            tts_path = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False).name
                            tts.save(tts_path)
                            st.audio(tts_path, format="audio/mp3")
                        except Exception as e:
                            st.error(f"тЭМ рдЖрд╡рд╛рдЬрд╝ рдмрдирд╛рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {e}")
            else:
                st.warning("тЪа рдХреЛрдИ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рдирд╣реАрдВ рдорд┐рд▓рд╛ред")
    else:
        st.info("ЁЯОд рд░рд┐рдХреЙрд░реНрдб рдмрдЯрди рджрдмрд╛рдПрдВ рдФрд░ рдмреЛрд▓реЗрдВ...")

    st.markdown("---")
    st.caption("тЬи Whisper + GPT + gTTS рд╕реЗ рд╕рдВрдЪрд╛рд▓рд┐рдд ЁЯЪА")
