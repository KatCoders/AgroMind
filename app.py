
import os
import io
import time
import json
import tempfile
import requests
import numpy as np
import pandas as pd
import streamlit as st
import logging
from typing import Optional, Tuple, Dict, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS
from voice_pipeline import *
from st_audiorec import st_audiorec
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
# ------------------- Safe TTS Warm-up -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load environment variables -------------------
load_dotenv()
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY", "").strip()


# ------------------- Page config & Enhanced CSS -------------------
st.set_page_config(
    page_title="üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï - ‡§Ü‡§™‡§ï‡§æ ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§ñ‡•á‡§§‡•Ä ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞"
    }
)

st.markdown("""
<style>
    .main-title { 
        text-align: center; 
        color: #2E8B57; 
        font-size: 2.2rem; 
        margin-bottom: 1rem; 
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .voice-section { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 12px; 
        color: white; 
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #28a745;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .status-success {
        background-color: #d4edda;
        color: #155724;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #c3e6cb;
    }
    .status-error {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #f5c6cb;
    }
    .status-info {
        background-color: #d1ecf1;
        color: #0c5460;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #bee5eb;
    }
    .loading-spinner {
        display: flex;
        justify-content: center;
        align-items: center;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)
# ------------------- Web Geolocation -------------------

def get_location_html():
    """Generate HTML for browser geolocation"""
    return """
    <div id="location-container">
        <button id="get-location-btn" onclick="getLocation()" 
                style="background: linear-gradient(45deg, #FF6B6B, #4ECDC4); 
                       color: white; padding: 10px 20px; border: none; 
                       border-radius: 20px; cursor: pointer;">
            üìç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§ü‡•Ä‡§ï ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç
        </button>
        <div id="location-status" style="margin-top: 10px; font-size: 14px;"></div>
    </div>

    <script>
    function getLocation() {
        const statusDiv = document.getElementById('location-status');
        const btn = document.getElementById('get-location-btn');
        
        if (navigator.geolocation) {
            btn.innerHTML = '‚è≥ ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...';
            btn.disabled = true;
            
            navigator.geolocation.getCurrentPosition(
                function(position) {
                    const lat = position.coords.latitude;
                    const lng = position.coords.longitude;
                    const accuracy = position.coords.accuracy;
                    
                    statusDiv.innerHTML = `
                        ‚úÖ ‡§∏‡•ç‡§•‡§æ‡§® ‡§Æ‡§ø‡§≤ ‡§ó‡§Ø‡§æ!<br>
                        üìç ‡§Ö‡§ï‡•ç‡§∑‡§æ‡§Ç‡§∂: ${lat.toFixed(4)}<br>
                        üìç ‡§¶‡•á‡§∂‡§æ‡§Ç‡§§‡§∞: ${lng.toFixed(4)}<br>
                        üéØ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ: ${Math.round(accuracy)}m
                    `;
                    
                    btn.innerHTML = '‚úÖ ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•ã ‡§ó‡§Ø‡§æ';
                },
                function(error) {
                    let errorMsg = '';
                    switch(error.code) {
                        case error.PERMISSION_DENIED:
                            errorMsg = '‚ùå ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä';
                            break;
                        case error.POSITION_UNAVAILABLE:
                            errorMsg = '‚ö†Ô∏è ‡§∏‡•ç‡§•‡§æ‡§® ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç';
                            break;
                        case error.TIMEOUT:
                            errorMsg = '‚è∞ ‡§∏‡§Æ‡§Ø ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§ ‡§π‡•ã ‡§ó‡§Ø‡§æ';
                            break;
                        default:
                            errorMsg = '‚ùå ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø';
                            break;
                    }
                    statusDiv.innerHTML = errorMsg + '<br><small>IP ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç</small>';
                    btn.innerHTML = 'üìç ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç';
                    btn.disabled = false;
                }
            );
        } else {
            statusDiv.innerHTML = '‚ùå ‡§Ø‡§π ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ geolocation ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡§æ';
        }
    }
    </script>
    """











# ------------------- Session state initialization -------------------
def init_session_state():
     """Initialize all session state variables"""
     if "app_initialized" not in st.session_state:
        st.session_state.update({
            "app_initialized": False,
            "tts_system_ready": False,
            "stt_warmed": False,
            "chat_history": [],
            "processing": False,
            "last_audio_data": None,
            "last_audio": None,
            "voice_enabled": True,
            "auto_play_response": True,
            "use_offline_tts": False,
            "location_method": "ip",
            "html_location": None,
            "warmup_status": "‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...",
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText()
        })

    

init_session_state()

if "tts_system" not in st.session_state:
    st.session_state.tts_system = UnifiedTTSSystem()

st.markdown('<h1 class="main-title">üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§π‡§ø‡§§)</h1>', unsafe_allow_html=True)
# Enhanced initialization with better UX
def perform_comprehensive_warmup():
    """Perform comprehensive system warmup with progress tracking"""
    if st.session_state.app_initialized:
        return True
    
    progress_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        warmup_steps = [
            ("üîß ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠...", 15),
            ("üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...", 35),
            ("üîä TTS ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§µ‡§æ‡§∞‡•ç‡§Æ ‡§Ö‡§™...", 55),
            ("üåê API ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ú‡§æ‡§Ç‡§ö...", 70),
            ("üìä ‡§°‡•á‡§ü‡§æ ‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡§®‡•á‡§ï‡•ç‡§ü...", 85),
            ("‚úÖ ‡§∏‡§≠‡•Ä ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§§‡•à‡§Ø‡§æ‡§∞!", 100)
        ]
        
        for step_text, progress_value in warmup_steps:
            status_text.markdown(f'<div class="warmup-status">{step_text}</div>', unsafe_allow_html=True)
            progress_bar.progress(progress_value)
            
            # Actual warmup operations
            if progress_value == 35:  # STT warmup simulation
                try:
                    test_response = requests.get(
                        "https://api.groq.com/openai/v1/models", 
                        headers={"Authorization": f"Bearer {GROQ_API_KEY}"}, 
                        timeout=5
                    )
                    if test_response.status_code == 200:
                        st.session_state.stt_warmed = True
                        st.session_state.warmup_status = "STT API ‡§§‡•à‡§Ø‡§æ‡§∞ ‚úÖ"
                    else:
                        st.session_state.warmup_status = "STT API ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‚ö†Ô∏è"
                except Exception as e:
                    st.session_state.stt_warmed = False
                    st.session_state.warmup_status = "STT API ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‚ö†Ô∏è"
                    logger.error(f"STT warmup failed: {e}")
            
            elif progress_value == 55:  # TTS warmup
                try:
                    tts_success = True
                    st.session_state.tts_system_ready = True

                    st.session_state.tts_system_ready = tts_success
                    if tts_success:
                        st.session_state.warmup_status = "TTS ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§§‡•à‡§Ø‡§æ‡§∞ ‚úÖ"
                    else:
                        st.session_state.warmup_status = "TTS ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‚ö†Ô∏è"
                except Exception as e:
                    logger.error(f"TTS warmup failed: {e}")
                    st.session_state.tts_system_ready = False
                    st.session_state.warmup_status = "TTS ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‚ùå"
            
            time.sleep(0.6)
        
        time.sleep(1)
        progress_container.empty()
    
    st.session_state.app_initialized = True
    return True
perform_comprehensive_warmup()

# ------------------- Enhanced utility functions -------------------
def get_default_soil_data() -> Dict[str, float]:
    """Return default soil data for fallback"""
    return {
        "ph": 6.5,
        "nitrogen": 50,
        "organic_carbon": 10,
        "sand": 40,
        "silt": 40,
        "clay": 20
    }

def get_default_weather_data() -> Dict[str, Any]:
    """Return default weather data for fallback"""
    return {
        "temperature": 25,
        "humidity": 70,
        "precipitation": 2,
        "wind_speed": 10,
        "condition": "‡§∏‡§æ‡§´‡§º"
    }

@st.cache_data(ttl=3600, show_spinner=False)
def get_user_location() -> Tuple[float, float, str]:
    """Get user location with HTML geolocation support"""
    # Check if HTML geolocation data is available
    if st.session_state.html_location:
        lat = st.session_state.html_location.get("lat", 28.61)
        lon = st.session_state.html_location.get("lng", 77.20)
        return lat, lon, "HTML Geolocation"
    
    # Fallback to IP-based location
    try:
        response = requests.get("https://ipinfo.io/json", timeout=8)
        if response.status_code == 200:
            data = response.json()
            loc = data.get("loc", "28.61,77.20").split(",")
            city = data.get("city", "‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä")
            region = data.get("region", "")
            
            location_name = f"{city}"
            if region and region != city:
                location_name += f", {region}"
                
            return float(loc[0]), float(loc[1]), location_name
    except Exception as e:
        logger.warning(f"Location fetch failed: {e}")
    
    return 28.61, 77.20, "‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä"  

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_soil(lat: float, lon: float) -> Dict[str, float]:
    """Fetch soil data with better error handling and realistic defaults"""
    try:
        # Using a more reliable approach for soil data
        url = "https://rest.isric.org/soilgrids/v2.0/properties"
        params = {
            "lon": lon,
            "lat": lat,
            "property": "phh2o",
            "depth": "0-5cm",
            "value": "mean"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            # For demo purposes, return realistic values based on location
            # In production, you would parse the actual SoilGrids response
            base_soil = get_default_soil_data()
            
            # Adjust values slightly based on location for realism
            lat_factor = (lat - 20) / 20  # Normalize around typical Indian latitudes
            
            base_soil["ph"] += lat_factor * 0.5
            base_soil["nitrogen"] += lat_factor * 10
            
            return base_soil
            
    except requests.RequestException as e:
        logger.warning(f"Soil data fetch failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in soil data fetch: {e}")
    
    return get_default_soil_data()

@st.cache_data(ttl=600, show_spinner=False)  # 10 minute cache for weather
def fetch_weather(lat: float, lon: float) -> Dict[str, Any]:
    """Fetch weather data with comprehensive error handling"""
    if not WEATHER_API_KEY:
        return get_default_weather_data()
        
    try:
        url = "http://api.weatherapi.com/v1/current.json"
        params = {
            "key": WEATHER_API_KEY,
            "q": f"{lat},{lon}",
            "aqi": "no"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            current = data.get("current", {})
            
            return {
                "temperature": current.get("temp_c", 25),
                "humidity": current.get("humidity", 70),
                "precipitation": current.get("precip_mm", 2),
                "wind_speed": current.get("wind_kph", 10),
                "condition": current.get("condition", {}).get("text", "‡§∏‡§æ‡§´‡§º"),
                "feels_like": current.get("feelslike_c", 25),
                "uv": current.get("uv", 5)
            }
        else:
            logger.warning(f"Weather API returned status {response.status_code}")
            
    except requests.RequestException as e:
        logger.warning(f"Weather data fetch failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in weather data fetch: {e}")
    
    return get_default_weather_data()

# ------------------- Enhanced ML model -------------------
@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    """Create and train enhanced ML model"""
    np.random.seed(42)
    n_samples = 2000  # More training data
    
    features = []
    labels = []
    
    # Generate more diverse and realistic training data
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        
        features.append([temp, humidity, ph, nitrogen])
        
        # Enhanced decision logic for crop recommendation
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)  # ‡§ó‡•á‡§π‡•Ç‡§Å
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)  # ‡§ß‡§æ‡§®
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)  # ‡§Æ‡§ï‡•ç‡§ï‡§æ
        else:
            # Random assignment for edge cases
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    
    # Feature scaling
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train model with better parameters
    clf = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    clf.fit(X_scaled, y)
    
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    """Get crop prediction with confidence score"""
    try:
        clf, scaler = get_trained_model()
        
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        
        crop_map = {0: "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1: "üå± ‡§ß‡§æ‡§®", 2: "üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
        confidence = float(max(probabilities) * 100)
        
        return crop_map.get(prediction, "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§"), confidence
        
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 75.0

# ------------------- Load environmental data -------------------
with st.spinner("üåç ‡§∏‡•ç‡§•‡§æ‡§® ‡§î‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§° ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
    lat, lon, city = get_user_location()
    soil_data = fetch_soil(lat, lon)
    weather_data = fetch_weather(lat, lon)

# ------------------- Enhanced Sidebar -------------------
with st.sidebar:
    st.header("üéõÔ∏è ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§™‡•à‡§®‡§≤")
    
    # Settings
    st.subheader("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏")
    st.session_state.voice_enabled = st.checkbox("üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡•ç‡§≤‡•á‡§¨‡•à‡§ï", value=st.session_state.voice_enabled)
    st.session_state.auto_play_response = st.checkbox("üéµ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§™‡•ç‡§≤‡•á‡§¨‡•à‡§ï", value=st.session_state.auto_play_response)
    
    response_length = st.selectbox(
        "‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•Ä ‡§≤‡§Ç‡§¨‡§æ‡§à",
        ["‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§", "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø", "‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§"],
        index=1
    )
    
    # Reset button with confirmation
    if st.button("‚ôªÔ∏è ‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", type="secondary"):
        if st.session_state.chat_history:
            st.session_state.chat_history = []
            st.success("‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§π‡•ã ‡§ó‡§à!")
            time.sleep(1)
            st.rerun()
        else:
            st.info("‡§ï‡•ã‡§à ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à")

    # Environmental data display
    st.header("üìä ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§°‡•á‡§ü‡§æ")
    st.success(f"üìç ‡§∏‡•ç‡§•‡§æ‡§®: {city}")

    with st.expander("üå± ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("pH ‡§∏‡•ç‡§§‡§∞", f"{soil_data.get('ph', 0):.1f}", 
                     delta=f"{soil_data.get('ph', 0) - 7.0:.1f} ‡§∏‡•á ‡§®‡•ç‡§Ø‡•Ç‡§ü‡•ç‡§∞‡§≤")
            st.metric("‡§∞‡•á‡§§ %", f"{soil_data.get('sand', 0):.0f}")
            st.metric("‡§ó‡§æ‡§¶ %", f"{soil_data.get('silt', 0):.0f}")
        with col2:
            st.metric("‡§®‡§æ‡§á‡§ü‡•ç‡§∞‡•ã‡§ú‡§®", f"{soil_data.get('nitrogen', 0):.0f}")
            st.metric("‡§ï‡§æ‡§∞‡•ç‡§¨‡§® %", f"{soil_data.get('organic_carbon', 0):.1f}")
            st.metric("‡§ö‡§ø‡§ï‡§®‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä %", f"{soil_data.get('clay', 0):.0f}")

    with st.expander("üå§Ô∏è ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("‡§§‡§æ‡§™‡§Æ‡§æ‡§®", f"{weather_data.get('temperature', 0):.1f}¬∞C")
            st.metric("‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§π‡•ã‡§§‡§æ ‡§π‡•à", f"{weather_data.get('feels_like', weather_data.get('temperature', 25)):.1f}¬∞C")
            st.metric("‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ", f"{weather_data.get('humidity', 0):.0f}%")
        with col2:
            st.metric("‡§¨‡§æ‡§∞‡§ø‡§∂", f"{weather_data.get('precipitation', 0):.1f}mm")
            st.metric("‡§π‡§µ‡§æ ‡§ï‡•Ä ‡§ó‡§§‡§ø", f"{weather_data.get('wind_speed', 0):.1f}km/h")
            if "uv" in weather_data:
                st.metric("UV ‡§∏‡•Ç‡§ö‡§ï‡§æ‡§Ç‡§ï", f"{weather_data.get('uv', 0):.0f}")
        
        st.info(f"‡§Æ‡•å‡§∏‡§Æ: {weather_data.get('condition', '‡§∏‡§æ‡§´‡§º')}")

    # Crop prediction
    predicted_crop, confidence = get_crop_prediction(soil_data, weather_data)
    st.success(f"üéØ ‡§∏‡•Å‡§ù‡§æ‡§à ‡§ó‡§à ‡§´‡§∏‡§≤: {predicted_crop}")
    
    # Enhanced confidence display
    confidence_color = "green" if confidence > 80 else "orange" if confidence > 60 else "red"
    st.markdown(f"‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∏‡•ç‡§§‡§∞: :{confidence_color}[{confidence:.1f}%]")

# ------------------- Enhanced Groq LLM setup -------------------

# ------------------- Voice Input Section -------------------
st.markdown('<div class="status-box"><h3>üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç</h3></div>', unsafe_allow_html=True)

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
   audio_file = st.file_uploader(
    "‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç üé§", 
    type=["wav", "mp3", "amr"]
)
if audio_file is not None:
    audio_bytes = audio_file.read()
    st.audio(audio_bytes, format="audio/wav")
    
    st.success("‚úÖ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§π‡•ã ‡§ó‡§Ø‡§æ!")
    time.sleep(5)
if audio_file and audio_file != st.session_state.last_audio and not st.session_state.processing:
    st.session_state.last_audio = audio_file
    st.session_state.processing = True
    
    try:
        # Step 1: Transcribe (STT)
        with st.spinner("üîÑ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
           audio_bytes = audio_file.read()
           
            
           voice_text = st.session_state.stt.transcribe(audio_bytes, filename="live_audio.wav", language="hi")
            
            
        
        if not voice_text:
            st.warning("‚ö†Ô∏è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∏‡§µ‡§æ‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç‡•§")
        else:
            # Display transcription
            st.success(f"‚úÖ ‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ: **{voice_text}**")
            
            # Save to chat history
            st.session_state.chat_history.append({
                "role": "user",
                "content": voice_text,
                "type": "voice",
                "timestamp": datetime.now().isoformat()
            })
            
            # Step 2: Get LLM Response
        with st.spinner("ü§î ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                response = get_llm_response(voice_text)
            
            # Step 3: Generate TTS
        if response and len(response) > 0:
                with st.spinner("üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                    audio_bytes = st.session_state.tts_system.generate_audio(response)
                
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3", autoplay=True)
                    st.success("‚úÖ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞!")
                else:
                    st.info("üí° ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§ñ‡•á‡§Ç (‡§Ü‡§µ‡§æ‡§ú‡§º ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç)")
    
    except Exception as e:
        st.error(f"‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {str(e)}")
        logger.error(f"Processing error: {e}", exc_info=True)
    
    finally:
        st.session_state.processing = False

else:
   st.markdown("""
<style>
.chat-container {
    background-color: #000000;  
    color: #FFFFFF;           
    padding: 20px;
    border-radius: 15px;
    box-shadow: 0px 4px 10px rgba(0,0,0,0.5);
    margin-top: 20px;
    margin-bottom: 20px;
    font-family: 'Segoe UI', sans-serif;
}
.chat-container h4 {
    font-size: 1.8rem;
    margin-bottom: 10px;
    color: #00FF7F;
}
.chat-container ul li {
    margin-bottom: 5px;
}
.chat-container em {
    color: #FFD700;
}
</style>

<div class="chat-container">
    <h4>üëã ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡§æ‡§à!</h4>
    <p>‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:</p>
    <ul>
        <li>üåæ <strong>‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂</strong> - ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§´‡§∏‡§≤ ‡§¨‡•ã‡§è‡§Ç</li>
        <li>üå± <strong>‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤</strong> - ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á</li>
        <li>üåßÔ∏è <strong>‡§Æ‡•å‡§∏‡§Æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡§≤‡§æ‡§π</strong> - ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ñ‡•á‡§§‡•Ä</li>
        <li>üêõ <strong>‡§ï‡•Ä‡§ü ‡§î‡§∞ ‡§∞‡•ã‡§ó ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£</strong> - ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®</li>
        <li>üíß <strong>‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®</strong> - ‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§∏‡§π‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ</li>
        <li>üåø <strong>‡§ú‡•à‡§µ‡§ø‡§ï ‡§ñ‡•á‡§§‡•Ä</strong> - ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§§‡§∞‡•Ä‡§ï‡•á</li>
    </ul>
    <p><em>‡§Ü‡§™ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≤‡§ø‡§ñ‡§ï‡§∞ ‡§Ø‡§æ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç!</em></p>
</div>
""", unsafe_allow_html=True)


# ------------------- Enhanced Text Input Section -------------------
def process_text_input(user_input: str):
    """Process text input using unified LLM function"""
    if st.session_state.processing:
        st.warning("‚è≥ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§è‡§ï ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§ö‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à...")
        return
    
    st.session_state.processing = True
    try:
        # Display user message
        with st.chat_message("user"):
            st.markdown(f"‚úçÔ∏è {user_input}")
        
        # Save to history
   
        # LLM response
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_placeholder.markdown("ü§ñ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç... üß†")
            
            full_response = ""
            try:
                for chunk in chain.stream({
                    "question": user_input,
                    "location": city,
                    "temperature": weather_data.get('temperature', 25),
                    "humidity": weather_data.get('humidity', 70),
                    "soil_ph": soil_data.get('ph', 6.5),
                    "nitrogen": soil_data.get('nitrogen', 50),
                    "crop_suggestion": predicted_crop,
                    "confidence": confidence
                }):
                    full_response += chunk
                    response_placeholder.markdown(f"ü§ñ {full_response}")
                    
            except Exception as e:
                error_msg = f"‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {str(e)}"
                response_placeholder.error(f"‚ùå {error_msg}")
                full_response = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§"
                logger.error(f"LLM generation error: {e}")
        
        st.session_state.chat_history.append({
            "role": "user", 
            "content": user_input, 
            "type": "text",
            "timestamp": datetime.now().isoformat()
        })
    
        # Generate audio - NO THREADING, direct call
        if st.session_state.voice_enabled and full_response:
            with st.spinner("üéß ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                audio_bytes = st.session_state.tts_system.generate_audio(full_response)

                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                    st.success("üîä ‡§§‡•à‡§Ø‡§æ‡§∞!")
                else:
                    st.info("üí° ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ‡§à ‡§ú‡§æ ‡§∏‡§ï‡•Ä‡•§")

    except Exception as e:
        st.error(f"‚ùå ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {str(e)}")
        logger.error(f"Text processing error: {e}")
    finally:
        st.session_state.processing = False

# Handle chat input
if user_input := st.chat_input("‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    process_text_input(user_input)

# ------------------- Enhanced Footer Section -------------------
st.markdown("---")

# Statistics and utilities
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_chats = len([m for m in st.session_state.chat_history if m["role"] == "user"])
    st.metric("üí¨ ‡§ï‡•Å‡§≤ ‡§∏‡§µ‡§æ‡§≤", total_chats)

with col2:
    voice_chats = len([m for m in st.session_state.chat_history if m.get("type") == "voice"])
    st.metric("üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º‡•Ä ‡§∏‡§µ‡§æ‡§≤", voice_chats)

with col3:
    if st.session_state.chat_history:
        last_chat_time = st.session_state.chat_history[-1].get("timestamp", "")
        if last_chat_time:
            st.metric("‚è∞ ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§µ‡§æ‡§≤", last_chat_time[:19].replace('T', ' '))
    else:
        st.metric("‚è∞ ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§µ‡§æ‡§≤", "‡§ï‡•ã‡§à ‡§®‡§π‡•Ä‡§Ç")

with col4:
    # Export chat functionality
    if st.button("üì• ‡§ö‡•à‡§ü ‡§è‡§ï‡•ç‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç"):
        if st.session_state.chat_history:
            chat_export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "location_info": {
                    "city": city,
                    "coordinates": [lat, lon],
                    "weather": weather_data,
                    "soil": soil_data
                },
                "crop_prediction": {
                    "recommended_crop": predicted_crop,
                    "confidence": confidence
                },
                "chat_history": st.session_state.chat_history,
                "statistics": {
                    "total_messages": len(st.session_state.chat_history),
                    "voice_messages": voice_chats,
                    "text_messages": total_chats - voice_chats
                }
            }
            
            # Create downloadable JSON
            json_str = json.dumps(chat_export_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="üíæ JSON ‡§´‡§º‡§æ‡§á‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
                data=json_str,
                file_name=f"agriculture_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•ã JSON ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§ï‡§∞‡•á‡§Ç"
            )
        else:
            st.info("‡§ï‡•ã‡§à ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à")

# Quick action buttons
st.markdown("### üöÄ ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®")
col1, col2, col3 = st.columns(3)

quick_questions = [
    "‡§á‡§∏ ‡§Æ‡•å‡§∏‡§Æ ‡§Æ‡•á‡§Ç ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§´‡§∏‡§≤ ‡§¨‡•á‡§π‡§§‡§∞ ‡§π‡•ã‡§ó‡•Ä?",
    "‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§ï‡•à‡§∏‡•á ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç?",
    "‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?"
]

for i, (col, question) in enumerate(zip([col1, col2, col3], quick_questions)):
    with col:
        if st.button(question, key=f"quick_q_{i}"):
            process_text_input(question)

# Help and information section
with st.expander("‚ÑπÔ∏è ‡§Æ‡§¶‡§¶ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
    st.markdown("""
    ### üîß ‡§ï‡•à‡§∏‡•á ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç:
    
    **‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è:**
    1. üé§ "‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°" ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    2. ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡•ã‡§≤‡•á‡§Ç
    3. "‡§∏‡•ç‡§ü‡•â‡§™" ‡§¶‡§¨‡§æ‡§ï‡§∞ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•á‡§Ç  
    4. "‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç" ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    
    **‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è:**
    1. ‡§®‡•Ä‡§ö‡•á ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç
    2. Enter ‡§¶‡§¨‡§æ‡§è‡§Ç ‡§Ø‡§æ ‡§≠‡•á‡§ú‡•á‡§Ç ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    
    ### üåæ ‡§Æ‡•à‡§Ç ‡§ï‡§ø‡§® ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç:
    - ‡§´‡§∏‡§≤ ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π (‡§Æ‡•å‡§∏‡§Æ ‡§î‡§∞ ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞)
    - ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á
    - ‡§ï‡•Ä‡§ü ‡§î‡§∞ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§∞‡•ã‡§ï‡§•‡§æ‡§Æ
    - ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§æ ‡§∏‡§π‡•Ä ‡§∏‡§Æ‡§Ø ‡§î‡§∞ ‡§§‡§∞‡•Ä‡§ï‡§æ
    - ‡§ñ‡§æ‡§¶ ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä
    - ‡§ú‡•à‡§µ‡§ø‡§ï ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•á ‡§®‡•Å‡§∏‡•ç‡§ñ‡•á
    - ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ
    
    ### ‚ö†Ô∏è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡•Ç‡§ö‡§®‡§æ:
    - ‡§Ø‡§π ‡§è‡§ï AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à ‡§î‡§∞ ‡§¶‡•Ä ‡§ó‡§à ‡§∏‡§≠‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ï‡•á‡§µ‡§≤ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§π‡•à‡§Ç
    - ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•É‡§∑‡§ø ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§≤‡•á‡§Ç
    - ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü ‡§∞‡•á‡§ü ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§≠‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à (‡§ú‡§≤‡•ç‡§¶ ‡§Ü‡§è‡§ó‡•Ä)
    
    ### üõ†Ô∏è ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ:
    - ‡§Ø‡§¶‡§ø ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡§π‡§ö‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§§‡•ã ‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç
    - ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ß‡•Ä‡§Æ‡§æ ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§•‡•ã‡§°‡§º‡§æ ‡§á‡§Ç‡§§‡§ú‡§º‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç
    - ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è "‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç" ‡§¨‡§ü‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
    """)

# Footer with credits and version info
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;'>
    <p>üåæ <strong>AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï(By AgroMind)</strong> - ‡§Ü‡§™‡§ï‡•á ‡§ñ‡•á‡§§ ‡§ï‡§æ ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§Æ‡§ø‡§§‡•ç‡§∞</p>
    <p><small>‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ 2.0 | Powered by Groq AI , SoilGrids & OpenWeatherMap</small></p>
    <p><small>
        ‡§∏‡§≠‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ï‡•á‡§µ‡§≤ ‡§∏‡•Ç‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡§Ç‡•§ 
        ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•É‡§∑‡§ø ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§≤‡•á‡§Ç‡•§
    </small></p>
</div>
""", unsafe_allow_html=True)






