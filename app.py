import os
import io
import time
import json
import tempfile
import requests
import numpy as np
import pandas as pd
import streamlit as st
import logging
from typing import Optional, Tuple, Dict, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS
from voice_pipeline import *
from st_audiorec import st_audiorec
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from voiceassit import voice_assistant_feature
import streamlit.components.v1 as components
from streamlit_geolocation import streamlit_geolocation 

# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ------------------- Safe TTS Warm-up -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load environment variables -------------------
load_dotenv()
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY", "").strip()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()

# ------------------- Page config & Enhanced CSS -------------------
st.set_page_config(
    page_title="ЁЯМ╛ AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ - рдЖрдкрдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдЦреЗрддреА рд╕рд▓рд╛рд╣рдХрд╛рд░"
    }
)

st.markdown("""
<style>
    .main-title { 
        text-align: center; 
        color: #2E8B57; 
        font-size: 2.2rem; 
        margin-bottom: 1rem; 
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .location-prompt {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3rem;
        border-radius: 20px;
        text-align: center;
        color: white;
        margin: 2rem auto;
        max-width: 600px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
    }
    .location-prompt h2 {
        font-size: 2rem;
        margin-bottom: 1rem;
    }
    .location-prompt p {
        font-size: 1.1rem;
        margin-bottom: 1.5rem;
        opacity: 0.9;
    }
    .location-icon {
        font-size: 4rem;
        margin-bottom: 1rem;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.1); }
    }
    .voice-section { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 12px; 
        color: white; 
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #28a745;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ------------------- Session state initialization -------------------
def init_session_state():
    """Initialize all session state variables"""
    if "app_initialized" not in st.session_state:
        st.session_state.update({
            "app_initialized": False,
            "location_granted": False,
            "tts_system_ready": False,
            "stt_warmed": False,
            "chat_history": [],
            "processing": False,
            "last_audio_data": None,
            "last_audio": None,
            "voice_enabled": True,
            "auto_play_response": True,
            "use_offline_tts": False,
            "location_method": "ip",
            "client_location": None,
            "warmup_status": "рдкреНрд░рд╛рд░рдВрдн рдХрд░ рд░рд╣реЗ рд╣реИрдВ...",
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText(),
            "user_lat": None,
            "user_lon": None,
            "user_city": None
        })

init_session_state()

# ------------------- Location Request Screen -------------------

def show_location_request_screen():
    """Display location permission request screen"""
    st.markdown('<h1 class="main-title">ЁЯМ╛ AI рдЖрдзрд╛рд░рд┐рдд рдлрд╕рд▓ рд╕рд▓рд╛рд╣ рд╕рд╣рд╛рдпрдХ</h1>', unsafe_allow_html=True)
    col1, col2, col3 = st.columns([2, 3, 1])
    with col1:
        pass
    with col3:
        pass
    with col2:
        st.markdown("<h5><b>рдХреГрдкрдпрд╛ рдЗрд╕ рд▓реЛрдЧреЛ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ</b></h5>", unsafe_allow_html=True)
        loc = streamlit_geolocation()
    st.markdown("""
    <div class="location-prompt">
        <div class="location-icon">ЁЯУН</div>
        <h2>рд╕реНрдерд╛рди рдХреА рдЕрдиреБрдорддрд┐ рдЪрд╛рд╣рд┐рдП</h2>
        <p>рдЖрдкрдХреА рд╕рдЯреАрдХ рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣ рдХреЗ рд▓рд┐рдП рд╣рдореЗрдВ рдЖрдкрдХреЗ рд╕реНрдерд╛рди рдХреА рдЬрд░реВрд░рдд рд╣реИред</p>
        <p style="font-size: 0.9rem;">
            тЬЕ рдореМрд╕рдо рдЖрдзрд╛рд░рд┐рдд рд╕рд▓рд╛рд╣<br>
            тЬЕ рд╕реНрдерд╛рдиреАрдп рдорд┐рдЯреНрдЯреА рдХреА рдЬрд╛рдирдХрд╛рд░реА<br>
            тЬЕ рдХреНрд╖реЗрддреНрд░реАрдп рдлрд╕рд▓ рд╕реБрдЭрд╛рд╡
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Check if location is received
    if loc and isinstance(loc, dict):
        lat = loc.get("latitude")
        lon = loc.get("longitude")
        
        if lat is not None and lon is not None:
            # Location granted - save to session state
            st.session_state.user_lat = lat
            st.session_state.user_lon = lon
            st.session_state.location_granted = True
            
            # Get city name
            try:
                response = requests.get(
                    "https://nominatim.openstreetmap.org/reverse",
                    params={
                        "lat": lat,
                        "lon": lon,
                        "format": "json",
                        "accept-language": "hi"
                    },
                    headers={"User-Agent": "AgroMind-App/1.0"},
                    timeout=5
                )
                if response.status_code == 200:
                    data = response.json()
                    address = data.get("address", {})
                    city = (address.get("city") or 
                           address.get("town") or 
                           address.get("village") or 
                           address.get("state_district") or
                           "рдЖрдкрдХрд╛ рд╕реНрдерд╛рди")
                    st.session_state.user_city = f"ЁЯУН {city}"
            except:
                st.session_state.user_city = "ЁЯУН рдЖрдкрдХрд╛ рд╕реНрдерд╛рди (GPS)"
            
            st.success("тЬЕ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛! рдРрдк рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
            time.sleep(1)
            st.rerun()
    else:
        # Show instruction and fallback option
        st.info("ЁЯСЖ рдХреГрдкрдпрд╛ рдЕрдкрдиреЗ рдмреНрд░рд╛рдЙрдЬрд╝рд░ рдореЗрдВ рд╕реНрдерд╛рди рдХреА рдЕрдиреБрдорддрд┐ рджреЗрдВ")
        
        st.markdown("---")
        st.markdown("### рдпрд╛")
        
        if st.button("ЁЯМР IP рдЖрдзрд╛рд░рд┐рдд рд╕реНрдерд╛рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ", type="secondary"):
            try:
                response = requests.get("https://ipinfo.io/json", timeout=8)
                if response.status_code == 200:
                    data = response.json()
                    loc_str = data.get("loc", "28.61,77.20").split(",")
                    city = data.get("city", "рджрд┐рд▓реНрд▓реА")
                    region = data.get("region", "")
                    
                    st.session_state.user_lat = float(loc_str[0])
                    st.session_state.user_lon = float(loc_str[1])
                    st.session_state.user_city = f"ЁЯМР {city}, {region} (IP)"
                    st.session_state.location_granted = True
                    
                    st.success("тЬЕ IP рдЖрдзрд╛рд░рд┐рдд рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛!")
                    time.sleep(1)
                    st.rerun()
            except Exception as e:
                st.error(f"тЭМ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рдирд╣реАрдВ рд╣реЛ рд╕рдХрд╛: {str(e)}")

# ------------------- Check Location Permission -------------------
if not st.session_state.location_granted:
    show_location_request_screen()
    st.stop()  # Stop execution until location is granted

# ------------------- Main App (Only loads after location permission) -------------------

# Now we have location, continue with the rest of your app
lat = st.session_state.user_lat
lon = st.session_state.user_lon
city = st.session_state.user_city

st.markdown('<h1 class="main-title">ЁЯМ╛ AI рдЖрдзрд╛рд░рд┐рдд рдлрд╕рд▓ рд╕рд▓рд╛рд╣ рд╕рд╣рд╛рдпрдХ (рд╣рд┐рдВрджреА, рдЖрд╡рд╛рдЬрд╝ рд╕рд╣рд┐рдд)</h1>', unsafe_allow_html=True)

# ------------------- Enhanced utility functions -------------------
def get_default_soil_data() -> Dict[str, float]:
    """Return default soil data for fallback"""
    return {
        "ph": 6.5,
        "nitrogen": 50,
        "organic_carbon": 10,
        "sand": 40,
        "silt": 40,
        "clay": 20
    }

def get_default_weather_data() -> Dict[str, Any]:
    """Return default weather data for fallback"""
    return {
        "temperature": 25,
        "humidity": 70,
        "precipitation": 2,
        "wind_speed": 10,
        "condition": "рд╕рд╛рдлрд╝"
    }

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_soil(lat: float, lon: float) -> Dict[str, float]:
    """Fetch soil data with better error handling and realistic defaults"""
    try:
        url = "https://rest.isric.org/soilgrids/v2.0/properties"
        params = {
            "lon": lon,
            "lat": lat,
            "property": "phh2o",
            "depth": "0-5cm",
            "value": "mean"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            base_soil = get_default_soil_data()
            lat_factor = (lat - 20) / 20
            base_soil["ph"] += lat_factor * 0.5
            base_soil["nitrogen"] += lat_factor * 10
            return base_soil
            
    except Exception as e:
        logger.error(f"Unexpected error in soil data fetch: {e}")
    
    return get_default_soil_data()

@st.cache_data(ttl=600, show_spinner=False)
def fetch_weather(lat: float, lon: float) -> Dict[str, Any]:
    """Fetch weather data with comprehensive error handling"""
    if not WEATHER_API_KEY:
        return get_default_weather_data()
        
    try:
        url = "http://api.weatherapi.com/v1/current.json"
        params = {
            "key": WEATHER_API_KEY,
            "q": f"{lat},{lon}",
            "aqi": "no"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            current = data.get("current", {})
            
            return {
                "temperature": current.get("temp_c", 25),
                "humidity": current.get("humidity", 70),
                "precipitation": current.get("precip_mm", 2),
                "wind_speed": current.get("wind_kph", 10),
                "condition": current.get("condition", {}).get("text", "рд╕рд╛рдлрд╝"),
                "feels_like": current.get("feelslike_c", 25),
                "uv": current.get("uv", 5)
            }
            
    except Exception as e:
        logger.error(f"Unexpected error in weather data fetch: {e}")
    
    return get_default_weather_data()

# ------------------- Enhanced ML model -------------------
@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    """Create and train enhanced ML model"""
    np.random.seed(42)
    n_samples = 2000
    
    features = []
    labels = []
    
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        
        features.append([temp, humidity, ph, nitrogen])
        
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)  # рдЧреЗрд╣реВрдБ
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)  # рдзрд╛рди
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)  # рдордХреНрдХрд╛
        else:
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    clf = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    clf.fit(X_scaled, y)
    
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    """Get crop prediction with confidence score"""
    try:
        clf, scaler = get_trained_model()
        
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        
        crop_map = {0: "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 1: "ЁЯМ▒ рдзрд╛рди", 2: "ЁЯМ╜ рдордХреНрдХрд╛"}
        confidence = float(max(probabilities) * 100)
        
        return crop_map.get(prediction, "тЭУ рдЕрдЬреНрдЮрд╛рдд"), confidence
        
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 75.0

# Enhanced initialization with better UX
def perform_comprehensive_warmup():
    """Perform comprehensive system warmup with progress tracking"""
    if st.session_state.app_initialized:
        return True
    
    progress_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        warmup_steps = [
            ("ЁЯФз рд╕рд┐рд╕реНрдЯрдо рдкреНрд░рд╛рд░рдВрдн...", 20),
            ("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕рд┐рд╕реНрдЯрдо рддреИрдпрд╛рд░...", 50),
            ("ЁЯФК TTS рд╕рд┐рд╕реНрдЯрдо рд╡рд╛рд░реНрдо рдЕрдк...", 70),
            ("ЁЯУК рдбреЗрдЯрд╛ рд▓реЛрдб...", 90),
            ("тЬЕ рддреИрдпрд╛рд░!", 100)
        ]
        
        for step_text, progress_value in warmup_steps:
            status_text.markdown(f'<div class="status-info">{step_text}</div>', unsafe_allow_html=True)
            progress_bar.progress(progress_value)
            time.sleep(0.3)
        
        time.sleep(0.5)
        progress_container.empty()
    
    st.session_state.app_initialized = True
    return True

perform_comprehensive_warmup()

# ------------------- Load environmental data -------------------
with st.spinner("ЁЯМН рдкрд░реНрдпрд╛рд╡рд░рдг рдбреЗрдЯрд╛ рд▓реЛрдб рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
    soil_data = fetch_soil(lat, lon)
    weather_data = fetch_weather(lat, lon)

# ------------------- Enhanced Groq LLM setup -------------------
@st.cache_resource(show_spinner=False)
def get_llm_chain():
    """Initialize Groq LLM with optimized settings"""
    try:
        if not GROQ_API_KEY:
            logger.error("GROQ_API_KEY not found in environment")
            return None
            
        llm = ChatGroq(
            temperature=0.7,
            model_name="llama-3.3-70b-versatile",
            groq_api_key=GROQ_API_KEY
        )
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """рдЖрдк рдПрдХ рдЕрдиреБрднрд╡реА рднрд╛рд░рддреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╣реИрдВред 
рдЖрдкрдХреЛ рдХрд┐рд╕рд╛рдиреЛрдВ рдХреЛ рдЙрдирдХреА рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рд╕рд▓рд╛рд╣ рджреЗрдиреА рд╣реИред

рд╡рд░реНрддрдорд╛рди рдбреЗрдЯрд╛:
- рд╕реНрдерд╛рди: {city}
- рдореМрд╕рдо: рддрд╛рдкрдорд╛рди {temperature}┬░C, рдЖрд░реНрджреНрд░рддрд╛ {humidity}%, рд╕реНрдерд┐рддрд┐: {condition}
- рдорд┐рдЯреНрдЯреА pH: {ph}, рдирд╛рдЗрдЯреНрд░реЛрдЬрди: {nitrogen}
- рд╕реБрдЭрд╛рдИ рдЧрдИ рдлрд╕рд▓: {predicted_crop} (рд╡рд┐рд╢реНрд╡рд╛рд╕: {confidence}%)

рд╣рдореЗрд╢рд╛ рд╣рд┐рдВрджреА рдореЗрдВ рд╕реНрдкрд╖реНрдЯ, рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдФрд░ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╕рд▓рд╛рд╣ рджреЗрдВред 
рдХрд┐рд╕рд╛рди рдХреА рднрд╛рд╖рд╛ рдореЗрдВ рдмрд╛рдд рдХрд░реЗрдВ рдФрд░ рд╕реАрдзреЗ рдореБрджреНрджреЗ рдкрд░ рдЖрдПрдВред
рдЕрдкрдиреЗ рдЬрд╡рд╛рдм рдореЗрдВ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдмрд┐рдВрджреБ рд╢рд╛рдорд┐рд▓ рдХрд░реЗрдВ рдЬрдм рдЙрдкрдпреБрдХреНрдд рд╣реЛ:
1. рддреБрд░рдВрдд рдХреНрдпрд╛ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП
2. рдХреНрдпреЛрдВ рдпрд╣ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ
3. рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд╕реБрдЭрд╛рд╡ рдпрд╛ рд╡рд┐рдХрд▓реНрдк

3-5 рд╡рд╛рдХреНрдпреЛрдВ рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВред"""),
            ("human", "{question}")
        ])
        
        chain = prompt_template | llm | StrOutputParser()
        return chain
        
    except Exception as e:
        logger.error(f"Failed to initialize LLM: {e}")
        return None

def get_llm_response(user_query: str) -> str:
    """Get response from LLM with context"""
    try:
        chain = get_llm_chain()
        if not chain:
            return "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, AI рд╕реЗрд╡рд╛ рдЕрднреА рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ GROQ_API_KEY рд╕реЗрдЯ рд╣реИред"
        
        # Get current crop prediction
        predicted_crop, confidence = get_crop_prediction(soil_data, weather_data)
        
        response = chain.invoke({
            "city": st.session_state.get("user_city", "рдЖрдкрдХрд╛ рд╕реНрдерд╛рди"),
            "temperature": weather_data.get("temperature", 25),
            "humidity": weather_data.get("humidity", 70),
            "condition": weather_data.get("condition", "рд╕рд╛рдлрд╝"),
            "ph": soil_data.get("ph", 6.5),
            "nitrogen": soil_data.get("nitrogen", 50),
            "predicted_crop": predicted_crop,
            "confidence": f"{confidence:.1f}",
            "question": user_query
        })
        
        return response.strip()
        
    except Exception as e:
        logger.error(f"LLM response error: {e}")
        return f"рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рдЖрдИ: {str(e)}\n\nрдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдкрдХреА .env рдлрд╛рдЗрд▓ рдореЗрдВ GROQ_API_KEY рд╕рд╣реА рддрд░реАрдХреЗ рд╕реЗ рд╕реЗрдЯ рд╣реИред"

# ------------------- Enhanced Sidebar -------------------
with st.sidebar:
    st.header("ЁЯОЫя╕П рдирд┐рдпрдВрддреНрд░рдг рдкреИрдирд▓")
    
    # Settings
    st.subheader("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕")
    st.session_state.voice_enabled = st.checkbox("ЁЯФК рдЖрд╡рд╛рдЬрд╝ рдкреНрд▓реЗрдмреИрдХ", value=st.session_state.voice_enabled)
    st.session_state.auto_play_response = st.checkbox("ЁЯО╡ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкреНрд▓реЗрдмреИрдХ", value=st.session_state.auto_play_response)
    
    response_length = st.selectbox(
        "рдЙрддреНрддрд░ рдХреА рд▓рдВрдмрд╛рдИ",
        ["рд╕рдВрдХреНрд╖рд┐рдкреНрдд", "рд╕рд╛рдорд╛рдиреНрдп", "рд╡рд┐рд╕реНрддреГрдд"],
        index=1
    )
    
    # Reset button with confirmation
    if st.button("тЩ╗я╕П рдЪреИрдЯ рд░реАрд╕реЗрдЯ рдХрд░реЗрдВ", type="secondary"):
        if st.session_state.chat_history:
            st.session_state.chat_history = []
            st.success("рдЪреИрдЯ рд░реАрд╕реЗрдЯ рд╣реЛ рдЧрдИ!")
            time.sleep(1)
            st.rerun()
        else:
            st.info("рдХреЛрдИ рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдирд╣реАрдВ рд╣реИ")

    # Environmental data display
    st.header("ЁЯУК рд╡рд░реНрддрдорд╛рди рдбреЗрдЯрд╛")
    st.success(f"ЁЯУН рд╕реНрдерд╛рди: {city}")

    with st.expander("ЁЯМ▒ рдорд┐рдЯреНрдЯреА рдХреА рд╡рд┐рд╕реНрддреГрдд рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("pH рд╕реНрддрд░", f"{soil_data.get('ph', 0):.1f}", 
                     delta=f"{soil_data.get('ph', 0) - 7.0:.1f} рд╕реЗ рдиреНрдпреВрдЯреНрд░рд▓")
            st.metric("рд░реЗрдд %", f"{soil_data.get('sand', 0):.0f}")
            st.metric("рдЧрд╛рдж %", f"{soil_data.get('silt', 0):.0f}")
        with col2:
            st.metric("рдирд╛рдЗрдЯреНрд░реЛрдЬрди", f"{soil_data.get('nitrogen', 0):.0f}")
            st.metric("рдХрд╛рд░реНрдмрди %", f"{soil_data.get('organic_carbon', 0):.1f}")
            st.metric("рдЪрд┐рдХрдиреА рдорд┐рдЯреНрдЯреА %", f"{soil_data.get('clay', 0):.0f}")

    with st.expander("ЁЯМдя╕П рдореМрд╕рдо рдХреА рд╡рд┐рд╕реНрддреГрдд рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("рддрд╛рдкрдорд╛рди", f"{weather_data.get('temperature', 0):.1f}┬░C")
            st.metric("рдорд╣рд╕реВрд╕ рд╣реЛрддрд╛ рд╣реИ", f"{weather_data.get('feels_like', weather_data.get('temperature', 25)):.1f}┬░C")
            st.metric("рдЖрд░реНрджреНрд░рддрд╛", f"{weather_data.get('humidity', 0):.0f}%")
        with col2:
            st.metric("рдмрд╛рд░рд┐рд╢", f"{weather_data.get('precipitation', 0):.1f}mm")
            st.metric("рд╣рд╡рд╛ рдХреА рдЧрддрд┐", f"{weather_data.get('wind_speed', 0):.1f}km/h")
            if "uv" in weather_data:
                st.metric("UV рд╕реВрдЪрдХрд╛рдВрдХ", f"{weather_data.get('uv', 0):.0f}")
        
        st.info(f"рдореМрд╕рдо: {weather_data.get('condition', 'рд╕рд╛рдлрд╝')}")

    # Crop prediction
    predicted_crop, confidence = get_crop_prediction(soil_data, weather_data)
    st.success(f"ЁЯОп рд╕реБрдЭрд╛рдИ рдЧрдИ рдлрд╕рд▓: {predicted_crop}")
    
    # Enhanced confidence display
    confidence_color = "green" if confidence > 80 else "orange" if confidence > 60 else "red"
    st.markdown(f"рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрддрд░: <span style='color:{confidence_color}; font-weight:bold'>{confidence:.1f}%</span>", unsafe_allow_html=True)

# ------------------- Voice Input Section -------------------

st.markdown("""
<style>
.chat-container {
    background-color: #000000;  
    color: #FFFFFF;           
    padding: 20px;
    border-radius: 15px;
    box-shadow: 0px 4px 10px rgba(0,0,0,0.5);
    margin-top: 20px;
    margin-bottom: 20px;
    font-family: 'Segoe UI', sans-serif;
}
.chat-container h4 {
    font-size: 1.8rem;
    margin-bottom: 10px;
    color: #00FF7F;
}
.chat-container ul li {
    margin-bottom: 5px;
}
.chat-container em {
    color: #FFD700;
}
</style>

<div class="chat-container">
    <h4>ЁЯСЛ рдирдорд╕реНрддреЗ рдХрд┐рд╕рд╛рди рднрд╛рдИ!</h4>
    <p>рдореИрдВ рдЖрдкрдХрд╛ AI рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реВрдВред рдЖрдк рдореБрдЭрд╕реЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд╡рд┐рд╖рдпреЛрдВ рдкрд░ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ:</p>
    <ul>
        <li>ЁЯМ╛ <strong>рдлрд╕рд▓ рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢</strong> - рдХреМрди рд╕реА рдлрд╕рд▓ рдмреЛрдПрдВ</li>
        <li>ЁЯМ▒ <strong>рдорд┐рдЯреНрдЯреА рдХреА рджреЗрдЦрднрд╛рд▓</strong> - рдорд┐рдЯреНрдЯреА рд╕реБрдзрд╛рд░ рдХреЗ рддрд░реАрдХреЗ</li>
        <li>ЁЯМзя╕П <strong>рдореМрд╕рдо рдЖрдзрд╛рд░рд┐рдд рд╕рд▓рд╛рд╣</strong> - рдореМрд╕рдо рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЦреЗрддреА</li>
        <li>ЁЯРЫ <strong>рдХреАрдЯ рдФрд░ рд░реЛрдЧ рдирд┐рдпрдВрддреНрд░рдг</strong> - рд╕рдорд╕реНрдпрд╛рдУрдВ рдХрд╛ рд╕рдорд╛рдзрд╛рди</li>
        <li>ЁЯТз <strong>рд╕рд┐рдВрдЪрд╛рдИ рдкреНрд░рдмрдВрдзрди</strong> - рдкрд╛рдиреА рдХреА рд╕рд╣реА рд╡реНрдпрд╡рд╕реНрдерд╛</li>
        <li>ЁЯМ┐ <strong>рдЬреИрд╡рд┐рдХ рдЦреЗрддреА</strong> - рдкреНрд░рд╛рдХреГрддрд┐рдХ рддрд░реАрдХреЗ</li>
    </ul>
    <p><em>рдЖрдк рдЯреЗрдХреНрд╕реНрдЯ рд▓рд┐рдЦрдХрд░ рдпрд╛ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ!</em></p>
</div>
""", unsafe_allow_html=True)
st.subheader("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫреЗрдВ")
st.caption("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдХреА рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (WAV/MP3)")

col1, col2, col3 = st.columns([1, 2, 1])

with col1:
    st.markdown("""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px; 
            border-radius: 16px; 
            box-shadow: 0 8px 16px rgba(0,0,0,0.15);
            margin-bottom: 20px;
        ">
            <h3 style="color: white; text-align: center; margin: 0;">
                ЁЯМ╛ рдХрд┐рд╕рд╛рди рд╕рд╣рд╛рдпрдХ рдкреЛрд░реНрдЯрд▓
            </h3>
        </div>
    """, unsafe_allow_html=True)
    
    # Tabs for different sections
    tab1, tab3 = st.tabs(["ЁЯУд рдЕрдкрд▓реЛрдб", "ЁЯТб рдЯрд┐рдкреНрд╕"])
    
    with tab1:
        st.markdown("""
            <div style="
                background-color: #f8f9fa;
                padding: 15px;
                border-radius: 12px;
                margin-bottom: 15px;
            ">
                <h4 style="color: #0d6efd; margin-bottom: 15px;">ЁЯУБ рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ</h4>
            </div>
        """, unsafe_allow_html=True)
        st.markdown("---")
    
    with tab3:
        st.markdown("""
            **тЬЕ рдХрд░реЗрдВ:**
            - ЁЯУ▒ рдорд╛рдЗрдХреНрд░реЛрдлреЛрди рдХреЗ рдкрд╛рд╕ рд░рд╣реЗрдВ (15-20 cm)
            - ЁЯФЗ рд╢рд╛рдВрдд рдЬрдЧрд╣ рдЪреБрдиреЗрдВ
            - ЁЯЧгя╕П рд╕реНрдкрд╖реНрдЯ рдФрд░ рдзреАрд░реЗ рдмреЛрд▓реЗрдВ
            - тП╕я╕П рд╢рдмреНрджреЛрдВ рдХреЗ рдмреАрдЪ рдЫреЛрдЯрд╛ pause рджреЗрдВ
        """)
        st.markdown("""
            **тЭМ рди рдХрд░реЗрдВ:**
            - ЁЯЪл рддреЗрдЬ рдЖрд╡рд╛рдЬ рдореЗрдВ рди рдЪрд┐рд▓реНрд▓рд╛рдПрдВ
            - ЁЯЪл рдмрд╣реБрдд рддреЗрдЬ рдпрд╛ рдмрд╣реБрдд рдзреАрд░реЗ рди рдмреЛрд▓реЗрдВ
            - ЁЯЪл рд╢реЛрд░ рд╡рд╛рд▓реА рдЬрдЧрд╣ рд╕реЗ рд░рд┐рдХреЙрд░реНрдб рди рдХрд░реЗрдВ
            - ЁЯЪл рдорд╛рдЗрдХ рдХреЛ рд╣рд╛рде рд╕реЗ рди рдврдХреЗрдВ
        """)

with col2:
    components.html(
    """
   <elevenlabs-convai agent-id="agent_9301k6w0hb3bf1zbf0pjd1wqwhex"></elevenlabs-convai>
   <script src="https://unpkg.com/@elevenlabs/convai-widget-embed" async type="text/javascript"></script>
    """,
    height=400,
)
    audio_file = st.file_uploader("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type=["wav", "mp3"])

if audio_file:
    wav_audio_data = audio_file.read()
    if wav_audio_data != st.session_state.get("last_audio_data"):
        st.session_state["last_audio_data"] = wav_audio_data
        st.audio(wav_audio_data, format="audio/wav" if audio_file.type=="audio/wav" else "audio/mp3")
        
        if not st.session_state.get("processing", False):
            st.session_state.processing = True
            try:
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(wav_audio_data)
                    tmp_file.flush()
                    tmp_path = tmp_file.name
                
                try:
                    # Transcribe using your existing STT
                    voice_text = st.session_state.stt.transcribe(tmp_path, language="hi")
                finally:
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
                
                # Process transcription
                if voice_text and voice_text.strip():
                    st.info(f"ЁЯУЭ **{voice_text}**")
                    
                    # LLM response
                    with st.spinner("ЁЯдЦ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                        response = get_llm_response(voice_text)
                    
                    st.success(f"ЁЯдЦ {response}")
                    
                    # Save to chat history
                    st.session_state.chat_history.append({
                        "role": "user",
                        "content": voice_text,
                        "type": "voice",
                        "timestamp": datetime.now().isoformat()
                    })
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": response,
                        "type": "text",
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    # TTS
                    if st.session_state.get("voice_enabled", False):
                        with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                            try:
                                audio_bytes = st.session_state.tts_system.generate_audio(response)
                                if audio_bytes:
                                    st.audio(audio_bytes, format="audio/mp3")
                                    st.success("ЁЯФК рддреИрдпрд╛рд░!")
                            except Exception as tts_error:
                                logger.warning(f"TTS failed: {tts_error}")
                                st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдкрдврд╝реЗрдВ")
                else:
                    st.warning("тЪая╕П рдЖрд╡рд╛рдЬрд╝ рд╕реНрдкрд╖реНрдЯ рдирд╣реАрдВ рдереА")
                    
            except Exception as e:
                st.error(f"тЭМ рддреНрд░реБрдЯрд┐: {str(e)}")
                logger.error(f"Voice error: {e}", exc_info=True)
            finally:
                st.session_state.processing = False

# ------------------- Enhanced Text Input Section -------------------
def process_text_input(user_input: str):
    """Process text input using unified LLM function"""
    if st.session_state.processing:
        st.warning("тП│ рдХреГрдкрдпрд╛ рдкреНрд░рддреАрдХреНрд╖рд╛ рдХрд░реЗрдВ, рдПрдХ рдкреНрд░реЛрд╕реЗрд╕ рдкрд╣рд▓реЗ рд╕реЗ рдЪрд▓ рд░рд╣реА рд╣реИ...")
        return
    
    st.session_state.processing = True
    try:
        # Display user message
        with st.chat_message("user"):
            st.markdown(f"тЬНя╕П {user_input}")
        
        # Save user message to history
        st.session_state.chat_history.append({
            "role": "user", 
            "content": user_input, 
            "type": "text",
            "timestamp": datetime.now().isoformat()
        })
    
        # LLM response
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_placeholder.markdown("ЁЯдЦ рд╕реЛрдЪ рд░рд╣рд╛ рд╣реВрдВ... ЁЯза")
            
            full_response = ""
            try:
                response = get_llm_response(user_input)
                full_response = response
                response_placeholder.markdown(f"ЁЯдЦ {full_response}")
                
                # Save assistant response to history
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": full_response,
                    "type": "text",
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                error_msg = f"рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}"
                response_placeholder.error(f"тЭМ {error_msg}")
                full_response = "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛ рдХреЗ рдХрд╛рд░рдг рдЬрд╡рд╛рдм рдирд╣реАрдВ рджреЗ рд╕рдХрд╛ред рдХреГрдкрдпрд╛ рдлрд┐рд░ рд╕реЗ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред"
                logger.error(f"LLM generation error: {e}")
        
        # Generate audio - NO THREADING, direct call
        if st.session_state.voice_enabled and full_response:
            with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                try:
                    audio_bytes = st.session_state.tts_system.generate_audio(full_response)

                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")
                        st.success("ЁЯФК рддреИрдпрд╛рд░!")
                    else:
                        st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рд╣реИ, рд▓реЗрдХрд┐рди рдЖрд╡рд╛рдЬрд╝ рдирд╣реАрдВ рдмрдирд╛рдИ рдЬрд╛ рд╕рдХреАред")
                except Exception as tts_error:
                    logger.warning(f"TTS generation failed: {tts_error}")
                    st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рд╣реИ")

    except Exception as e:
        st.error(f"тЭМ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}")
        logger.error(f"Text processing error: {e}")
    finally:
        st.session_state.processing = False

# Display chat history
if st.session_state.chat_history:
    st.markdown("---")
    st.subheader("ЁЯТм рдмрд╛рддрдЪреАрдд рдХрд╛ рдЗрддрд┐рд╣рд╛рд╕")
    
    for message in st.session_state.chat_history:
        role = message.get("role", "user")
        content = message.get("content", "")
        msg_type = message.get("type", "text")
        
        with st.chat_message(role):
            icon = "ЁЯОд" if msg_type == "voice" else "тЬНя╕П"
            if role == "user":
                st.markdown(f"{icon} {content}")
            else:
                st.markdown(f"ЁЯдЦ {content}")

# Handle chat input
if user_input := st.chat_input("тЬНя╕П рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ..."):
    process_text_input(user_input)

# ------------------- Enhanced Footer Section -------------------
st.markdown("---")

# Statistics and utilities
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_chats = len([m for m in st.session_state.chat_history if m["role"] == "user"])
    st.metric("ЁЯТм рдХреБрд▓ рд╕рд╡рд╛рд▓", total_chats)

with col2:
    voice_chats = len([m for m in st.session_state.chat_history if m.get("type") == "voice"])
    st.metric("ЁЯОд рдЖрд╡рд╛рдЬрд╝реА рд╕рд╡рд╛рд▓", voice_chats)

with col3:
    if st.session_state.chat_history:
        last_chat_time = st.session_state.chat_history[-1].get("timestamp", "")
        if last_chat_time:
            st.metric("тП░ рдЕрдВрддрд┐рдо рд╕рд╡рд╛рд▓", last_chat_time[:19].replace('T', ' '))
    else:
        st.metric("тП░ рдЕрдВрддрд┐рдо рд╕рд╡рд╛рд▓", "рдХреЛрдИ рдирд╣реАрдВ")

with col4:
    # Export chat functionality
    if st.button("ЁЯУе рдЪреИрдЯ рдПрдХреНрд╕рдкреЛрд░реНрдЯ рдХрд░реЗрдВ"):
        if st.session_state.chat_history:
            chat_export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "location_info": {
                    "city": city,
                    "coordinates": [lat, lon],
                    "weather": weather_data,
                    "soil": soil_data
                },
                "crop_prediction": {
                    "recommended_crop": predicted_crop,
                    "confidence": confidence
                },
                "chat_history": st.session_state.chat_history,
                "statistics": {
                    "total_messages": len(st.session_state.chat_history),
                    "voice_messages": voice_chats,
                    "text_messages": total_chats - voice_chats
                }
            }
            
            # Create downloadable JSON
            json_str = json.dumps(chat_export_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="ЁЯТ╛ JSON рдлрд╝рд╛рдЗрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
                data=json_str,
                file_name=f"agriculture_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="рдЕрдкрдиреА рдкреВрд░реА рдмрд╛рддрдЪреАрдд рдХреЛ JSON рдлрд╝рд╛рдЗрд▓ рдХреЗ рд░реВрдк рдореЗрдВ рд╕реЗрд╡ рдХрд░реЗрдВ"
            )
        else:
            st.info("рдХреЛрдИ рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдирд╣реАрдВ рд╣реИ")

# Quick action buttons
st.markdown("### ЁЯЪА рддреНрд╡рд░рд┐рдд рдкреНрд░рд╢реНрди")
col1, col2, col3 = st.columns(3)

quick_questions = [
    "рдЗрд╕ рдореМрд╕рдо рдореЗрдВ рдХреМрди рд╕реА рдлрд╕рд▓ рдмреЗрд╣рддрд░ рд╣реЛрдЧреА?",
    "рдорд┐рдЯреНрдЯреА рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдХреИрд╕реЗ рд╕реБрдзрд╛рд░реЗрдВ?",
    "рдмрд╛рд░рд┐рд╢ рдХреЗ рдмрд╛рдж рдХреНрдпрд╛ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП?"
]

for i, (col, question) in enumerate(zip([col1, col2, col3], quick_questions)):
    with col:
        if st.button(question, key=f"quick_q_{i}"):
            process_text_input(question)

# Help and information section
with st.expander("тД╣я╕П рдорджрдж рдФрд░ рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
    st.markdown("""
    ### ЁЯФз рдХреИрд╕реЗ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд░реЗрдВ:

    **рдЖрд╡рд╛рдЬрд╝ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫрдиреЗ рдХреЗ рд▓рд┐рдП:**
    1. ЁЯОд "рд░рд┐рдХреЙрд░реНрдб" рдмрдЯрди рджрдмрд╛рдПрдВ
    2. рд╕реНрдкрд╖реНрдЯ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рдмреЛрд▓реЗрдВ
    3. "рд╕реНрдЯреЙрдк" рджрдмрд╛рдХрд░ рд░рд┐рдХреЙрд░реНрдбрд┐рдВрдЧ рдмрдВрдж рдХрд░реЗрдВ  
    4. "рдЬрд╡рд╛рдм рдкрд╛рдПрдВ" рдмрдЯрди рджрдмрд╛рдПрдВ

    **рдЯреЗрдХреНрд╕реНрдЯ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫрдиреЗ рдХреЗ рд▓рд┐рдП:**
    1. рдиреАрдЪреЗ рдЯреЗрдХреНрд╕реНрдЯ рдмреЙрдХреНрд╕ рдореЗрдВ рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рд▓рд┐рдЦреЗрдВ
    2. Enter рджрдмрд╛рдПрдВ рдпрд╛ рднреЗрдЬреЗрдВ рдмрдЯрди рджрдмрд╛рдПрдВ

    ### ЁЯМ╛ рдореИрдВ рдХрд┐рди рд╡рд┐рд╖рдпреЛрдВ рдореЗрдВ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ:
    - рдлрд╕рд▓ рдЪреБрдирдиреЗ рдХреА рд╕рд▓рд╛рд╣ (рдореМрд╕рдо рдФрд░ рдорд┐рдЯреНрдЯреА рдХреЗ рдЕрдиреБрд╕рд╛рд░)
    - рдорд┐рдЯреНрдЯреА рд╕реБрдзрд╛рд░ рдХреЗ рддрд░реАрдХреЗ
    - рдХреАрдЯ рдФрд░ рдмреАрдорд╛рд░реА рдХреА рд░реЛрдХрдерд╛рдо
    - рд╕рд┐рдВрдЪрд╛рдИ рдХрд╛ рд╕рд╣реА рд╕рдордп рдФрд░ рддрд░реАрдХрд╛
    - рдЦрд╛рдж рдФрд░ рдЙрд░реНрд╡рд░рдХ рдХреА рдЬрд╛рдирдХрд╛рд░реА
    - рдЬреИрд╡рд┐рдХ рдЦреЗрддреА рдХреЗ рдиреБрд╕реНрдЦреЗ
    - рдореМрд╕рдо рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЦреЗрддреА рдХреА рдпреЛрдЬрдирд╛

    ### тЪая╕П рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕реВрдЪрдирд╛:
    - рдпрд╣ рдПрдХ AI рд╕рд╣рд╛рдпрдХ рд╣реИ рдФрд░ рджреА рдЧрдИ рд╕рднреА рд╕рд▓рд╛рд╣ рдХреЗрд╡рд▓ рд╕реБрдЭрд╛рд╡ рд╣реИрдВ
    - рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХреГрд╖рд┐ рдирд┐рд░реНрдгрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рд▓реЗрдВ
    - рдорд╛рд░реНрдХреЗрдЯ рд░реЗрдЯ рдХреА рдЬрд╛рдирдХрд╛рд░реА рдЕрднреА рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИ (рдЬрд▓реНрдж рдЖрдПрдЧреА)

    ### ЁЯЫая╕П рддрдХрдиреАрдХреА рд╕рд╣рд╛рдпрддрд╛:
    - рдпрджрд┐ рдЖрд╡рд╛рдЬрд╝ рдкрд╣рдЪрд╛рди рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рд╣реЛ рддреЛ рд╢рд╛рдВрдд рдЬрдЧрд╣ рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВ
    - рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрд╢рди рдзреАрдорд╛ рд╣реЛрдиреЗ рдкрд░ рдереЛрдбрд╝рд╛ рдЗрдВрддрдЬрд╝рд╛рд░ рдХрд░реЗрдВ
    - рдХрд┐рд╕реА рднреА рд╕рдорд╕реНрдпрд╛ рдХреЗ рд▓рд┐рдП "рдЪреИрдЯ рд░реАрд╕реЗрдЯ рдХрд░реЗрдВ" рдмрдЯрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ
    
    ### ЁЯФС API Keys рдЖрд╡рд╢реНрдпрдХ:
    - рдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдкрдХреА .env рдлрд╝рд╛рдЗрд▓ рдореЗрдВ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд keys рд╣реИрдВ:
    - `GROQ_API_KEY` - Groq AI рдХреЗ рд▓рд┐рдП (рдореБрдлреНрдд рдореЗрдВ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ: https://console.groq.com)
    - `WEATHER_API_KEY` - WeatherAPI рдХреЗ рд▓рд┐рдП (рдореБрдлреНрдд рдореЗрдВ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ: https://www.weatherapi.com)
    """)

# Footer with credits and version info
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;'>
    <p>ЁЯМ╛ <strong>AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ (By AgroMind)</strong> - рдЖрдкрдХреЗ рдЦреЗрдд рдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдорд┐рддреНрд░</p>
    <p><small>рд╕рдВрд╕реНрдХрд░рдг 2.0 | Powered by Groq AI, SoilGrids & WeatherAPI</small></p>
    <p><small>
        рд╕рднреА рд╕рд▓рд╛рд╣ рдХреЗрд╡рд▓ рд╕реВрдЪрдирд╛рддреНрдордХ рдЙрджреНрджреЗрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╣реИрдВред 
        рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХреГрд╖рд┐ рдирд┐рд░реНрдгрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдЕрд╡рд╢реНрдп рд▓реЗрдВред
    </small></p>
</div>
""", unsafe_allow_html=True)
