
import os
import io
import time
import json
import tempfile
import requests
import numpy as np
import pandas as pd
import streamlit as st
import logging
from typing import Optional, Tuple, Dict, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS
from voice_pipeline import *
from st_audiorec import st_audiorec
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from voiceassit import voice_assistant_feature

# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
# ------------------- Safe TTS Warm-up -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load environment variables -------------------
load_dotenv()
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY", "").strip()


# ------------------- Page config & Enhanced CSS -------------------
st.set_page_config(
    page_title="ЁЯМ╛ AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ - рдЖрдкрдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдЦреЗрддреА рд╕рд▓рд╛рд╣рдХрд╛рд░"
    }
)

st.markdown("""
<style>
    .main-title { 
        text-align: center; 
        color: #2E8B57; 
        font-size: 2.2rem; 
        margin-bottom: 1rem; 
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .voice-section { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 12px; 
        color: white; 
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #28a745;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .status-success {
        background-color: #d4edda;
        color: #155724;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #c3e6cb;
    }
    .status-error {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #f5c6cb;
    }
    .status-info {
        background-color: #d1ecf1;
        color: #0c5460;
        padding: 0.5rem;
        border-radius: 4px;
        border: 1px solid #bee5eb;
    }
    .loading-spinner {
        display: flex;
        justify-content: center;
        align-items: center;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)
# ------------------- Web Geolocation -------------------

def get_location_html():
    """Generate HTML for browser geolocation"""
    return """
    <div id="location-container">
        <button id="get-location-btn" onclick="getLocation()" 
                style="background: linear-gradient(45deg, #FF6B6B, #4ECDC4); 
                       color: white; padding: 10px 20px; border: none; 
                       border-radius: 20px; cursor: pointer;">
            ЁЯУН рдЕрдкрдирд╛ рд╕рдЯреАрдХ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ
        </button>
        <div id="location-status" style="margin-top: 10px; font-size: 14px;"></div>
    </div>

    <script>
    function getLocation() {
        const statusDiv = document.getElementById('location-status');
        const btn = document.getElementById('get-location-btn');
        
        if (navigator.geolocation) {
            btn.innerHTML = 'тП│ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рдХрд░ рд░рд╣реЗ рд╣реИрдВ...';
            btn.disabled = true;
            
            navigator.geolocation.getCurrentPosition(
                function(position) {
                    const lat = position.coords.latitude;
                    const lng = position.coords.longitude;
                    const accuracy = position.coords.accuracy;
                    
                    statusDiv.innerHTML = `
                        тЬЕ рд╕реНрдерд╛рди рдорд┐рд▓ рдЧрдпрд╛!<br>
                        ЁЯУН рдЕрдХреНрд╖рд╛рдВрд╢: ${lat.toFixed(4)}<br>
                        ЁЯУН рджреЗрд╢рд╛рдВрддрд░: ${lng.toFixed(4)}<br>
                        ЁЯОп рд╕рдЯреАрдХрддрд╛: ${Math.round(accuracy)}m
                    `;
                    
                    btn.innerHTML = 'тЬЕ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛';
                },
                function(error) {
                    let errorMsg = '';
                    switch(error.code) {
                        case error.PERMISSION_DENIED:
                            errorMsg = 'тЭМ рд╕реНрдерд╛рди рдХреА рдЕрдиреБрдорддрд┐ рдирд╣реАрдВ рдорд┐рд▓реА';
                            break;
                        case error.POSITION_UNAVAILABLE:
                            errorMsg = 'тЪая╕П рд╕реНрдерд╛рди рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ';
                            break;
                        case error.TIMEOUT:
                            errorMsg = 'тП░ рд╕рдордп рд╕рдорд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛';
                            break;
                        default:
                            errorMsg = 'тЭМ рдЕрдЬреНрдЮрд╛рдд рддреНрд░реБрдЯрд┐';
                            break;
                    }
                    statusDiv.innerHTML = errorMsg + '<br><small>IP рдЖрдзрд╛рд░рд┐рдд рд╕реНрдерд╛рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд░рд╣реЗ рд╣реИрдВ</small>';
                    btn.innerHTML = 'ЁЯУН рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВ';
                    btn.disabled = false;
                }
            );
        } else {
            statusDiv.innerHTML = 'тЭМ рдпрд╣ рдмреНрд░рд╛рдЙрдЬрд╝рд░ geolocation рд╕рдорд░реНрдерд┐рдд рдирд╣реАрдВ рдХрд░рддрд╛';
        }
    }
    </script>
    """











# ------------------- Session state initialization -------------------
def init_session_state():
     """Initialize all session state variables"""
     if "app_initialized" not in st.session_state:
        st.session_state.update({
            "app_initialized": False,
            "tts_system_ready": False,
            "stt_warmed": False,
            "chat_history": [],
            "processing": False,
            "last_audio_data": None,
            "last_audio": None,
            "voice_enabled": True,
            "auto_play_response": True,
            "use_offline_tts": False,
            "location_method": "ip",
            "html_location": None,
            "warmup_status": "рдкреНрд░рд╛рд░рдВрдн рдХрд░ рд░рд╣реЗ рд╣реИрдВ...",
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText()
        })

    

init_session_state()

if "tts_system" not in st.session_state:
    st.session_state.tts_system = UnifiedTTSSystem()

st.markdown('<h1 class="main-title">ЁЯМ╛ AI рдЖрдзрд╛рд░рд┐рдд рдлрд╕рд▓ рд╕рд▓рд╛рд╣ рд╕рд╣рд╛рдпрдХ (рд╣рд┐рдВрджреА, рдЖрд╡рд╛рдЬрд╝ рд╕рд╣рд┐рдд)</h1>', unsafe_allow_html=True)
# Enhanced initialization with better UX
def perform_comprehensive_warmup():
    """Perform comprehensive system warmup with progress tracking"""
    if st.session_state.app_initialized:
        return True
    
    progress_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        warmup_steps = [
            ("ЁЯФз рд╕рд┐рд╕реНрдЯрдо рдкреНрд░рд╛рд░рдВрдн...", 15),
            ("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕рд┐рд╕реНрдЯрдо рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ...", 35),
            ("ЁЯФК TTS рд╕рд┐рд╕реНрдЯрдо рд╡рд╛рд░реНрдо рдЕрдк...", 55),
            ("ЁЯМР API рдХрдиреЗрдХреНрд╢рди рдЬрд╛рдВрдЪ...", 70),
            ("ЁЯУК рдбреЗрдЯрд╛ рд╕реЛрд░реНрд╕ рдХрдиреЗрдХреНрдЯ...", 85),
            ("тЬЕ рд╕рднреА рд╕рд┐рд╕реНрдЯрдо рддреИрдпрд╛рд░!", 100)
        ]
        
        for step_text, progress_value in warmup_steps:
            status_text.markdown(f'<div class="warmup-status">{step_text}</div>', unsafe_allow_html=True)
            progress_bar.progress(progress_value)
            
            # Actual warmup operations
            if progress_value == 35:  # STT warmup simulation
                try:
                    test_response = requests.get(
                        "https://api.groq.com/openai/v1/models", 
                        headers={"Authorization": f"Bearer {GROQ_API_KEY}"}, 
                        timeout=5
                    )
                    if test_response.status_code == 200:
                        st.session_state.stt_warmed = True
                        st.session_state.warmup_status = "STT API рддреИрдпрд╛рд░ тЬЕ"
                    else:
                        st.session_state.warmup_status = "STT API рдореЗрдВ рд╕рдорд╕реНрдпрд╛ тЪая╕П"
                except Exception as e:
                    st.session_state.stt_warmed = False
                    st.session_state.warmup_status = "STT API рдореЗрдВ рд╕рдорд╕реНрдпрд╛ тЪая╕П"
                    logger.error(f"STT warmup failed: {e}")
            
            elif progress_value == 55:  # TTS warmup
                try:
                    tts_success = True
                    st.session_state.tts_system_ready = True

                    st.session_state.tts_system_ready = tts_success
                    if tts_success:
                        st.session_state.warmup_status = "TTS рд╕рд┐рд╕реНрдЯрдо рддреИрдпрд╛рд░ тЬЕ"
                    else:
                        st.session_state.warmup_status = "TTS рд╕рд┐рд╕реНрдЯрдо рдореЗрдВ рд╕рдорд╕реНрдпрд╛ тЪая╕П"
                except Exception as e:
                    logger.error(f"TTS warmup failed: {e}")
                    st.session_state.tts_system_ready = False
                    st.session_state.warmup_status = "TTS рддреНрд░реБрдЯрд┐ тЭМ"
            
            time.sleep(0.6)
        
        time.sleep(1)
        progress_container.empty()
    
    st.session_state.app_initialized = True
    return True
perform_comprehensive_warmup()

# ------------------- Enhanced utility functions -------------------
def get_default_soil_data() -> Dict[str, float]:
    """Return default soil data for fallback"""
    return {
        "ph": 6.5,
        "nitrogen": 50,
        "organic_carbon": 10,
        "sand": 40,
        "silt": 40,
        "clay": 20
    }

def get_default_weather_data() -> Dict[str, Any]:
    """Return default weather data for fallback"""
    return {
        "temperature": 25,
        "humidity": 70,
        "precipitation": 2,
        "wind_speed": 10,
        "condition": "рд╕рд╛рдлрд╝"
    }

@st.cache_data(ttl=3600, show_spinner=False)
def get_user_location() -> Tuple[float, float, str]:
    """Get user location with HTML geolocation support"""
    # Check if HTML geolocation data is available
    if st.session_state.html_location:
        lat = st.session_state.html_location.get("lat", 28.61)
        lon = st.session_state.html_location.get("lng", 77.20)
        return lat, lon, "HTML Geolocation"
    
    # Fallback to IP-based location
    try:
        response = requests.get("https://ipinfo.io/json", timeout=8)
        if response.status_code == 200:
            data = response.json()
            loc = data.get("loc", "28.61,77.20").split(",")
            city = data.get("city", "рджрд┐рд▓реНрд▓реА")
            region = data.get("region", "")
            
            location_name = f"{city}"
            if region and region != city:
                location_name += f", {region}"
                
            return float(loc[0]), float(loc[1]), location_name
    except Exception as e:
        logger.warning(f"Location fetch failed: {e}")
    
    return 28.61, 77.20, "рджрд┐рд▓реНрд▓реА"  

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_soil(lat: float, lon: float) -> Dict[str, float]:
    """Fetch soil data with better error handling and realistic defaults"""
    try:
        # Using a more reliable approach for soil data
        url = "https://rest.isric.org/soilgrids/v2.0/properties"
        params = {
            "lon": lon,
            "lat": lat,
            "property": "phh2o",
            "depth": "0-5cm",
            "value": "mean"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            # For demo purposes, return realistic values based on location
            # In production, you would parse the actual SoilGrids response
            base_soil = get_default_soil_data()
            
            # Adjust values slightly based on location for realism
            lat_factor = (lat - 20) / 20  # Normalize around typical Indian latitudes
            
            base_soil["ph"] += lat_factor * 0.5
            base_soil["nitrogen"] += lat_factor * 10
            
            return base_soil
            
    except requests.RequestException as e:
        logger.warning(f"Soil data fetch failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in soil data fetch: {e}")
    
    return get_default_soil_data()

@st.cache_data(ttl=600, show_spinner=False)  # 10 minute cache for weather
def fetch_weather(lat: float, lon: float) -> Dict[str, Any]:
    """Fetch weather data with comprehensive error handling"""
    if not WEATHER_API_KEY:
        return get_default_weather_data()
        
    try:
        url = "http://api.weatherapi.com/v1/current.json"
        params = {
            "key": WEATHER_API_KEY,
            "q": f"{lat},{lon}",
            "aqi": "no"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            current = data.get("current", {})
            
            return {
                "temperature": current.get("temp_c", 25),
                "humidity": current.get("humidity", 70),
                "precipitation": current.get("precip_mm", 2),
                "wind_speed": current.get("wind_kph", 10),
                "condition": current.get("condition", {}).get("text", "рд╕рд╛рдлрд╝"),
                "feels_like": current.get("feelslike_c", 25),
                "uv": current.get("uv", 5)
            }
        else:
            logger.warning(f"Weather API returned status {response.status_code}")
            
    except requests.RequestException as e:
        logger.warning(f"Weather data fetch failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in weather data fetch: {e}")
    
    return get_default_weather_data()

# ------------------- Enhanced ML model -------------------
@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    """Create and train enhanced ML model"""
    np.random.seed(42)
    n_samples = 2000  # More training data
    
    features = []
    labels = []
    
    # Generate more diverse and realistic training data
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        
        features.append([temp, humidity, ph, nitrogen])
        
        # Enhanced decision logic for crop recommendation
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)  # рдЧреЗрд╣реВрдБ
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)  # рдзрд╛рди
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)  # рдордХреНрдХрд╛
        else:
            # Random assignment for edge cases
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    
    # Feature scaling
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train model with better parameters
    clf = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    clf.fit(X_scaled, y)
    
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    """Get crop prediction with confidence score"""
    try:
        clf, scaler = get_trained_model()
        
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        
        crop_map = {0: "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 1: "ЁЯМ▒ рдзрд╛рди", 2: "ЁЯМ╜ рдордХреНрдХрд╛"}
        confidence = float(max(probabilities) * 100)
        
        return crop_map.get(prediction, "тЭУ рдЕрдЬреНрдЮрд╛рдд"), confidence
        
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 75.0

# ------------------- Load environmental data -------------------
with st.spinner("ЁЯМН рд╕реНрдерд╛рди рдФрд░ рдкрд░реНрдпрд╛рд╡рд░рдг рдбреЗрдЯрд╛ рд▓реЛрдб рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
    lat, lon, city = get_user_location()
    soil_data = fetch_soil(lat, lon)
    weather_data = fetch_weather(lat, lon)

# ------------------- Enhanced Sidebar -------------------
with st.sidebar:
    st.header("ЁЯОЫя╕П рдирд┐рдпрдВрддреНрд░рдг рдкреИрдирд▓")
    
    # Settings
    st.subheader("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕")
    st.session_state.voice_enabled = st.checkbox("ЁЯФК рдЖрд╡рд╛рдЬрд╝ рдкреНрд▓реЗрдмреИрдХ", value=st.session_state.voice_enabled)
    st.session_state.auto_play_response = st.checkbox("ЁЯО╡ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкреНрд▓реЗрдмреИрдХ", value=st.session_state.auto_play_response)
    
    response_length = st.selectbox(
        "рдЙрддреНрддрд░ рдХреА рд▓рдВрдмрд╛рдИ",
        ["рд╕рдВрдХреНрд╖рд┐рдкреНрдд", "рд╕рд╛рдорд╛рдиреНрдп", "рд╡рд┐рд╕реНрддреГрдд"],
        index=1
    )
    
    # Reset button with confirmation
    if st.button("тЩ╗я╕П рдЪреИрдЯ рд░реАрд╕реЗрдЯ рдХрд░реЗрдВ", type="secondary"):
        if st.session_state.chat_history:
            st.session_state.chat_history = []
            st.success("рдЪреИрдЯ рд░реАрд╕реЗрдЯ рд╣реЛ рдЧрдИ!")
            time.sleep(1)
            st.rerun()
        else:
            st.info("рдХреЛрдИ рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдирд╣реАрдВ рд╣реИ")

    # Environmental data display
    st.header("ЁЯУК рд╡рд░реНрддрдорд╛рди рдбреЗрдЯрд╛")
    st.success(f"ЁЯУН рд╕реНрдерд╛рди: {city}")

    with st.expander("ЁЯМ▒ рдорд┐рдЯреНрдЯреА рдХреА рд╡рд┐рд╕реНрддреГрдд рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("pH рд╕реНрддрд░", f"{soil_data.get('ph', 0):.1f}", 
                     delta=f"{soil_data.get('ph', 0) - 7.0:.1f} рд╕реЗ рдиреНрдпреВрдЯреНрд░рд▓")
            st.metric("рд░реЗрдд %", f"{soil_data.get('sand', 0):.0f}")
            st.metric("рдЧрд╛рдж %", f"{soil_data.get('silt', 0):.0f}")
        with col2:
            st.metric("рдирд╛рдЗрдЯреНрд░реЛрдЬрди", f"{soil_data.get('nitrogen', 0):.0f}")
            st.metric("рдХрд╛рд░реНрдмрди %", f"{soil_data.get('organic_carbon', 0):.1f}")
            st.metric("рдЪрд┐рдХрдиреА рдорд┐рдЯреНрдЯреА %", f"{soil_data.get('clay', 0):.0f}")

    with st.expander("ЁЯМдя╕П рдореМрд╕рдо рдХреА рд╡рд┐рд╕реНрддреГрдд рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("рддрд╛рдкрдорд╛рди", f"{weather_data.get('temperature', 0):.1f}┬░C")
            st.metric("рдорд╣рд╕реВрд╕ рд╣реЛрддрд╛ рд╣реИ", f"{weather_data.get('feels_like', weather_data.get('temperature', 25)):.1f}┬░C")
            st.metric("рдЖрд░реНрджреНрд░рддрд╛", f"{weather_data.get('humidity', 0):.0f}%")
        with col2:
            st.metric("рдмрд╛рд░рд┐рд╢", f"{weather_data.get('precipitation', 0):.1f}mm")
            st.metric("рд╣рд╡рд╛ рдХреА рдЧрддрд┐", f"{weather_data.get('wind_speed', 0):.1f}km/h")
            if "uv" in weather_data:
                st.metric("UV рд╕реВрдЪрдХрд╛рдВрдХ", f"{weather_data.get('uv', 0):.0f}")
        
        st.info(f"рдореМрд╕рдо: {weather_data.get('condition', 'рд╕рд╛рдлрд╝')}")

    # Crop prediction
    predicted_crop, confidence = get_crop_prediction(soil_data, weather_data)
    st.success(f"ЁЯОп рд╕реБрдЭрд╛рдИ рдЧрдИ рдлрд╕рд▓: {predicted_crop}")
    
    # Enhanced confidence display
    confidence_color = "green" if confidence > 80 else "orange" if confidence > 60 else "red"
    st.markdown(f"рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрддрд░: :{confidence_color}[{confidence:.1f}%]")

# ------------------- Enhanced Groq LLM setup -------------------

# ------------------- Voice Input Section -------------------
st.subheader("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫреЗрдВ")
st.caption("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдХреА рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (WAV/MP3)")

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    voice_assistant_feature()
    audio_file = st.file_uploader("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type=["wav", "mp3"])

if audio_file:
    wav_audio_data = audio_file.read()
    if wav_audio_data != st.session_state.get("last_audio_data"):
        st.session_state["last_audio_data"] = wav_audio_data
        st.audio(wav_audio_data, format="audio/wav" if audio_file.type=="audio/wav" else "audio/mp3")
        
        if not st.session_state.get("processing", False):
            st.session_state.processing = True
            try:
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(wav_audio_data)
                    tmp_file.flush()
                    tmp_path = tmp_file.name
                
                try:
                    # Transcribe using your existing STT
                    voice_text = st.session_state.stt.transcribe(tmp_path, language="hi")
                finally:
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
                
                # Process transcription
                if voice_text and voice_text.strip():
                    st.info(f"ЁЯУЭ **{voice_text}**")
                    
                    # LLM response
                with st.spinner("ЁЯдЦ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                        response = get_llm_response(voice_text)
                    
                
                        
                        # TTS
                if st.session_state.get("voice_enabled", False):
                     with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                                try:
                                    audio_bytes = st.session_state.tts_system.generate_audio(response)
                                    if audio_bytes:
                                        st.audio(audio_bytes, format="audio/mp3")
                                        st.success("ЁЯФК рддреИрдпрд╛рд░!")
                                except Exception as tts_error:
                                    logger.warning(f"TTS failed: {tts_error}")
                                    st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдкрдврд╝реЗрдВ")
                          
                else:
                    st.warning("тЪая╕П рдЖрд╡рд╛рдЬрд╝ рд╕реНрдкрд╖реНрдЯ рдирд╣реАрдВ рдереА")
                    
            except Exception as e:
                st.error(f"тЭМ рддреНрд░реБрдЯрд┐: {str(e)}")
                logger.error(f"Voice error: {e}", exc_info=True)
            finally:
                st.session_state.processing = False

else:
   st.markdown("""
<style>
.chat-container {
    background-color: #000000;  
    color: #FFFFFF;           
    padding: 20px;
    border-radius: 15px;
    box-shadow: 0px 4px 10px rgba(0,0,0,0.5);
    margin-top: 20px;
    margin-bottom: 20px;
    font-family: 'Segoe UI', sans-serif;
}
.chat-container h4 {
    font-size: 1.8rem;
    margin-bottom: 10px;
    color: #00FF7F;
}
.chat-container ul li {
    margin-bottom: 5px;
}
.chat-container em {
    color: #FFD700;
}
</style>

<div class="chat-container">
    <h4>ЁЯСЛ рдирдорд╕реНрддреЗ рдХрд┐рд╕рд╛рди рднрд╛рдИ!</h4>
    <p>рдореИрдВ рдЖрдкрдХрд╛ AI рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реВрдВред рдЖрдк рдореБрдЭрд╕реЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд╡рд┐рд╖рдпреЛрдВ рдкрд░ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ:</p>
    <ul>
        <li>ЁЯМ╛ <strong>рдлрд╕рд▓ рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢</strong> - рдХреМрди рд╕реА рдлрд╕рд▓ рдмреЛрдПрдВ</li>
        <li>ЁЯМ▒ <strong>рдорд┐рдЯреНрдЯреА рдХреА рджреЗрдЦрднрд╛рд▓</strong> - рдорд┐рдЯреНрдЯреА рд╕реБрдзрд╛рд░ рдХреЗ рддрд░реАрдХреЗ</li>
        <li>ЁЯМзя╕П <strong>рдореМрд╕рдо рдЖрдзрд╛рд░рд┐рдд рд╕рд▓рд╛рд╣</strong> - рдореМрд╕рдо рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЦреЗрддреА</li>
        <li>ЁЯРЫ <strong>рдХреАрдЯ рдФрд░ рд░реЛрдЧ рдирд┐рдпрдВрддреНрд░рдг</strong> - рд╕рдорд╕реНрдпрд╛рдУрдВ рдХрд╛ рд╕рдорд╛рдзрд╛рди</li>
        <li>ЁЯТз <strong>рд╕рд┐рдВрдЪрд╛рдИ рдкреНрд░рдмрдВрдзрди</strong> - рдкрд╛рдиреА рдХреА рд╕рд╣реА рд╡реНрдпрд╡рд╕реНрдерд╛</li>
        <li>ЁЯМ┐ <strong>рдЬреИрд╡рд┐рдХ рдЦреЗрддреА</strong> - рдкреНрд░рд╛рдХреГрддрд┐рдХ рддрд░реАрдХреЗ</li>
    </ul>
    <p><em>рдЖрдк рдЯреЗрдХреНрд╕реНрдЯ рд▓рд┐рдЦрдХрд░ рдпрд╛ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ!</em></p>
</div>
""", unsafe_allow_html=True)


# ------------------- Enhanced Text Input Section -------------------
def process_text_input(user_input: str):
    """Process text input using unified LLM function"""
    if st.session_state.processing:
        st.warning("тП│ рдХреГрдкрдпрд╛ рдкреНрд░рддреАрдХреНрд╖рд╛ рдХрд░реЗрдВ, рдПрдХ рдкреНрд░реЛрд╕реЗрд╕ рдкрд╣рд▓реЗ рд╕реЗ рдЪрд▓ рд░рд╣реА рд╣реИ...")
        return
    
    st.session_state.processing = True
    try:
        # Display user message
        with st.chat_message("user"):
            st.markdown(f"тЬНя╕П {user_input}")
        
        # Save to history
   
        # LLM response
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_placeholder.markdown("ЁЯдЦ рд╕реЛрдЪ рд░рд╣рд╛ рд╣реВрдВ... ЁЯза")
            
            full_response = ""
            try:
                for chunk in chain.stream({
                    "question": user_input,
                    "location": city,
                    "temperature": weather_data.get('temperature', 25),
                    "humidity": weather_data.get('humidity', 70),
                    "soil_ph": soil_data.get('ph', 6.5),
                    "nitrogen": soil_data.get('nitrogen', 50),
                    "crop_suggestion": predicted_crop,
                    "confidence": confidence
                }):
                    full_response += chunk
                    response_placeholder.markdown(f"ЁЯдЦ {full_response}")
                    
            except Exception as e:
                error_msg = f"рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}"
                response_placeholder.error(f"тЭМ {error_msg}")
                full_response = "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛ рдХреЗ рдХрд╛рд░рдг рдЬрд╡рд╛рдм рдирд╣реАрдВ рджреЗ рд╕рдХрд╛ред рдХреГрдкрдпрд╛ рдлрд┐рд░ рд╕реЗ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред"
                logger.error(f"LLM generation error: {e}")
        
        st.session_state.chat_history.append({
            "role": "user", 
            "content": user_input, 
            "type": "text",
            "timestamp": datetime.now().isoformat()
        })
    
        # Generate audio - NO THREADING, direct call
        if st.session_state.voice_enabled and full_response:
            with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                audio_bytes = st.session_state.tts_system.generate_audio(full_response)

                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                    st.success("ЁЯФК рддреИрдпрд╛рд░!")
                else:
                    st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рд╣реИ, рд▓реЗрдХрд┐рди рдЖрд╡рд╛рдЬрд╝ рдирд╣реАрдВ рдмрдирд╛рдИ рдЬрд╛ рд╕рдХреАред")

    except Exception as e:
        st.error(f"тЭМ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}")
        logger.error(f"Text processing error: {e}")
    finally:
        st.session_state.processing = False

# Handle chat input
if user_input := st.chat_input("тЬНя╕П рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ..."):
    process_text_input(user_input)

# ------------------- Enhanced Footer Section -------------------
st.markdown("---")

# Statistics and utilities
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_chats = len([m for m in st.session_state.chat_history if m["role"] == "user"])
    st.metric("ЁЯТм рдХреБрд▓ рд╕рд╡рд╛рд▓", total_chats)

with col2:
    voice_chats = len([m for m in st.session_state.chat_history if m.get("type") == "voice"])
    st.metric("ЁЯОд рдЖрд╡рд╛рдЬрд╝реА рд╕рд╡рд╛рд▓", voice_chats)

with col3:
    if st.session_state.chat_history:
        last_chat_time = st.session_state.chat_history[-1].get("timestamp", "")
        if last_chat_time:
            st.metric("тП░ рдЕрдВрддрд┐рдо рд╕рд╡рд╛рд▓", last_chat_time[:19].replace('T', ' '))
    else:
        st.metric("тП░ рдЕрдВрддрд┐рдо рд╕рд╡рд╛рд▓", "рдХреЛрдИ рдирд╣реАрдВ")

with col4:
    # Export chat functionality
    if st.button("ЁЯУе рдЪреИрдЯ рдПрдХреНрд╕рдкреЛрд░реНрдЯ рдХрд░реЗрдВ"):
        if st.session_state.chat_history:
            chat_export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "location_info": {
                    "city": city,
                    "coordinates": [lat, lon],
                    "weather": weather_data,
                    "soil": soil_data
                },
                "crop_prediction": {
                    "recommended_crop": predicted_crop,
                    "confidence": confidence
                },
                "chat_history": st.session_state.chat_history,
                "statistics": {
                    "total_messages": len(st.session_state.chat_history),
                    "voice_messages": voice_chats,
                    "text_messages": total_chats - voice_chats
                }
            }
            
            # Create downloadable JSON
            json_str = json.dumps(chat_export_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="ЁЯТ╛ JSON рдлрд╝рд╛рдЗрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
                data=json_str,
                file_name=f"agriculture_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="рдЕрдкрдиреА рдкреВрд░реА рдмрд╛рддрдЪреАрдд рдХреЛ JSON рдлрд╝рд╛рдЗрд▓ рдХреЗ рд░реВрдк рдореЗрдВ рд╕реЗрд╡ рдХрд░реЗрдВ"
            )
        else:
            st.info("рдХреЛрдИ рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдирд╣реАрдВ рд╣реИ")

# Quick action buttons
st.markdown("### ЁЯЪА рддреНрд╡рд░рд┐рдд рдкреНрд░рд╢реНрди")
col1, col2, col3 = st.columns(3)

quick_questions = [
    "рдЗрд╕ рдореМрд╕рдо рдореЗрдВ рдХреМрди рд╕реА рдлрд╕рд▓ рдмреЗрд╣рддрд░ рд╣реЛрдЧреА?",
    "рдорд┐рдЯреНрдЯреА рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдХреИрд╕реЗ рд╕реБрдзрд╛рд░реЗрдВ?",
    "рдмрд╛рд░рд┐рд╢ рдХреЗ рдмрд╛рдж рдХреНрдпрд╛ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП?"
]

for i, (col, question) in enumerate(zip([col1, col2, col3], quick_questions)):
    with col:
        if st.button(question, key=f"quick_q_{i}"):
            process_text_input(question)

# Help and information section
with st.expander("тД╣я╕П рдорджрдж рдФрд░ рдЬрд╛рдирдХрд╛рд░реА", expanded=False):
    st.markdown("""
    ### ЁЯФз рдХреИрд╕реЗ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд░реЗрдВ:
    
    **рдЖрд╡рд╛рдЬрд╝ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫрдиреЗ рдХреЗ рд▓рд┐рдП:**
    1. ЁЯОд "рд░рд┐рдХреЙрд░реНрдб" рдмрдЯрди рджрдмрд╛рдПрдВ
    2. рд╕реНрдкрд╖реНрдЯ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рдмреЛрд▓реЗрдВ
    3. "рд╕реНрдЯреЙрдк" рджрдмрд╛рдХрд░ рд░рд┐рдХреЙрд░реНрдбрд┐рдВрдЧ рдмрдВрдж рдХрд░реЗрдВ  
    4. "рдЬрд╡рд╛рдм рдкрд╛рдПрдВ" рдмрдЯрди рджрдмрд╛рдПрдВ
    
    **рдЯреЗрдХреНрд╕реНрдЯ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫрдиреЗ рдХреЗ рд▓рд┐рдП:**
    1. рдиреАрдЪреЗ рдЯреЗрдХреНрд╕реНрдЯ рдмреЙрдХреНрд╕ рдореЗрдВ рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рд▓рд┐рдЦреЗрдВ
    2. Enter рджрдмрд╛рдПрдВ рдпрд╛ рднреЗрдЬреЗрдВ рдмрдЯрди рджрдмрд╛рдПрдВ
    
    ### ЁЯМ╛ рдореИрдВ рдХрд┐рди рд╡рд┐рд╖рдпреЛрдВ рдореЗрдВ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ:
    - рдлрд╕рд▓ рдЪреБрдирдиреЗ рдХреА рд╕рд▓рд╛рд╣ (рдореМрд╕рдо рдФрд░ рдорд┐рдЯреНрдЯреА рдХреЗ рдЕрдиреБрд╕рд╛рд░)
    - рдорд┐рдЯреНрдЯреА рд╕реБрдзрд╛рд░ рдХреЗ рддрд░реАрдХреЗ
    - рдХреАрдЯ рдФрд░ рдмреАрдорд╛рд░реА рдХреА рд░реЛрдХрдерд╛рдо
    - рд╕рд┐рдВрдЪрд╛рдИ рдХрд╛ рд╕рд╣реА рд╕рдордп рдФрд░ рддрд░реАрдХрд╛
    - рдЦрд╛рдж рдФрд░ рдЙрд░реНрд╡рд░рдХ рдХреА рдЬрд╛рдирдХрд╛рд░реА
    - рдЬреИрд╡рд┐рдХ рдЦреЗрддреА рдХреЗ рдиреБрд╕реНрдЦреЗ
    - рдореМрд╕рдо рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЦреЗрддреА рдХреА рдпреЛрдЬрдирд╛
    
    ### тЪая╕П рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕реВрдЪрдирд╛:
    - рдпрд╣ рдПрдХ AI рд╕рд╣рд╛рдпрдХ рд╣реИ рдФрд░ рджреА рдЧрдИ рд╕рднреА рд╕рд▓рд╛рд╣ рдХреЗрд╡рд▓ рд╕реБрдЭрд╛рд╡ рд╣реИрдВ
    - рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХреГрд╖рд┐ рдирд┐рд░реНрдгрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рд▓реЗрдВ
    - рдорд╛рд░реНрдХреЗрдЯ рд░реЗрдЯ рдХреА рдЬрд╛рдирдХрд╛рд░реА рдЕрднреА рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИ (рдЬрд▓реНрдж рдЖрдПрдЧреА)
    
    ### ЁЯЫая╕П рддрдХрдиреАрдХреА рд╕рд╣рд╛рдпрддрд╛:
    - рдпрджрд┐ рдЖрд╡рд╛рдЬрд╝ рдкрд╣рдЪрд╛рди рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рд╣реЛ рддреЛ рд╢рд╛рдВрдд рдЬрдЧрд╣ рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВ
    - рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрд╢рди рдзреАрдорд╛ рд╣реЛрдиреЗ рдкрд░ рдереЛрдбрд╝рд╛ рдЗрдВрддрдЬрд╝рд╛рд░ рдХрд░реЗрдВ
    - рдХрд┐рд╕реА рднреА рд╕рдорд╕реНрдпрд╛ рдХреЗ рд▓рд┐рдП "рдЪреИрдЯ рд░реАрд╕реЗрдЯ рдХрд░реЗрдВ" рдмрдЯрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ
    """)

# Footer with credits and version info
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;'>
    <p>ЁЯМ╛ <strong>AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ(By AgroMind)</strong> - рдЖрдкрдХреЗ рдЦреЗрдд рдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдорд┐рддреНрд░</p>
    <p><small>рд╕рдВрд╕реНрдХрд░рдг 2.0 | Powered by Groq AI , SoilGrids & OpenWeatherMap</small></p>
    <p><small>
        рд╕рднреА рд╕рд▓рд╛рд╣ рдХреЗрд╡рд▓ рд╕реВрдЪрдирд╛рддреНрдордХ рдЙрджреНрджреЗрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╣реИрдВред 
        рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХреГрд╖рд┐ рдирд┐рд░реНрдгрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдЕрд╡рд╢реНрдп рд▓реЗрдВред
    </small></p>
</div>
""", unsafe_allow_html=True)
