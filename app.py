import os
import io
import time
import json
import tempfile
import requests
import numpy as np
import pandas as pd
import streamlit as st
import logging
from typing import Optional, Tuple, Dict, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS
from voice_pipeline import *
from st_audiorec import st_audiorec
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from voiceassit import voice_assistant_feature
import streamlit.components.v1 as components
from streamlit_geolocation import streamlit_geolocation 

# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ------------------- Safe TTS Warm-up -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load environment variables -------------------
load_dotenv()
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY", "").strip()

# ------------------- Page config & Enhanced CSS -------------------
st.set_page_config(
    page_title="üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï - ‡§Ü‡§™‡§ï‡§æ ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§ñ‡•á‡§§‡•Ä ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞"
    }
)

st.markdown("""
<style>
    .main-title { 
        text-align: center; 
        color: #2E8B57; 
        font-size: 2.2rem; 
        margin-bottom: 1rem; 
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .location-prompt {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3rem;
        border-radius: 20px;
        text-align: center;
        color: white;
        margin: 2rem auto;
        max-width: 600px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
    }
    .location-prompt h2 {
        font-size: 2rem;
        margin-bottom: 1rem;
    }
    .location-prompt p {
        font-size: 1.1rem;
        margin-bottom: 1.5rem;
        opacity: 0.9;
    }
    .location-icon {
        font-size: 4rem;
        margin-bottom: 1rem;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.1); }
    }
    .voice-section { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 12px; 
        color: white; 
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #28a745;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ------------------- Session state initialization -------------------
def init_session_state():
    """Initialize all session state variables"""
    if "app_initialized" not in st.session_state:
        st.session_state.update({
            "app_initialized": False,
            "location_granted": False,
            "tts_system_ready": False,
            "stt_warmed": False,
            "chat_history": [],
            "processing": False,
            "last_audio_data": None,
            "last_audio": None,
            "voice_enabled": True,
            "auto_play_response": True,
            "use_offline_tts": False,
            "location_method": "ip",
            "client_location": None,
            "warmup_status": "‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...",
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText(),
            "user_lat": None,
            "user_lon": None,
            "user_city": None
        })

init_session_state()

# ------------------- Location Request Screen -------------------

  
def show_location_request_screen():
    """Display location permission request screen"""
    st.markdown('<h1 class="main-title">üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï</h1>', unsafe_allow_html=True)
    col1, col2, col3 = st.columns([2, 3, 1])
    with col1:
        pass
    with col3:
        pass
    with col2:
        st.markdown("<h5><b>‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§∏ ‡§≤‡•ã‡§ó‡•ã ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç</b></h5>", unsafe_allow_html=True)
        loc = streamlit_geolocation()
    st.markdown("""
    <div class="location-prompt">
        <div class="location-icon">üìç</div>
        <h2>‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§ö‡§æ‡§π‡§ø‡§è</h2>
        <p>‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§ü‡•Ä‡§ï ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§ ‡§π‡•à‡•§</p>
        <p style="font-size: 0.9rem;">
            ‚úÖ ‡§Æ‡•å‡§∏‡§Æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡§≤‡§æ‡§π<br>
            ‚úÖ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä<br>
            ‚úÖ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•Ä‡§Ø ‡§´‡§∏‡§≤ ‡§∏‡•Å‡§ù‡§æ‡§µ
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Get location using streamlit_geolocation
   
    # Check if location is received
    if loc and isinstance(loc, dict):
        lat = loc.get("latitude")
        lon = loc.get("longitude")
        
        if lat is not None and lon is not None:
            # Location granted - save to session state
            st.session_state.user_lat = lat
            st.session_state.user_lon = lon
            st.session_state.location_granted = True
            
            # Get city name
            try:
                response = requests.get(
                    "https://nominatim.openstreetmap.org/reverse",
                    params={
                        "lat": lat,
                        "lon": lon,
                        "format": "json",
                        "accept-language": "hi"
                    },
                    headers={"User-Agent": "AgroMind-App/1.0"},
                    timeout=5
                )
                if response.status_code == 200:
                    data = response.json()
                    address = data.get("address", {})
                    city = (address.get("city") or 
                           address.get("town") or 
                           address.get("village") or 
                           address.get("state_district") or
                           "‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§•‡§æ‡§®")
                    st.session_state.user_city = f"üìç {city}"
            except:
                st.session_state.user_city = "üìç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§•‡§æ‡§® (GPS)"
            
            st.success("‚úÖ ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•ã ‡§ó‡§Ø‡§æ! ‡§ê‡§™ ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...")
            time.sleep(1)
            st.rerun()
    else:
        # Show instruction and fallback option
        st.info("üëÜ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç")
        
        st.markdown("---")
        st.markdown("### ‡§Ø‡§æ")
        
        if st.button("üåê IP ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç", type="secondary"):
            try:
                response = requests.get("https://ipinfo.io/json", timeout=8)
                if response.status_code == 200:
                    data = response.json()
                    loc_str = data.get("loc", "28.61,77.20").split(",")
                    city = data.get("city", "‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä")
                    region = data.get("region", "")
                    
                    st.session_state.user_lat = float(loc_str[0])
                    st.session_state.user_lon = float(loc_str[1])
                    st.session_state.user_city = f"üåê {city}, {region} (IP)"
                    st.session_state.location_granted = True
                    
                    st.success("‚úÖ IP ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•ã ‡§ó‡§Ø‡§æ!")
                    time.sleep(1)
                    st.rerun()
            except Exception as e:
                st.error(f"‚ùå ‡§∏‡•ç‡§•‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§æ: {str(e)}")

# ------------------- Check Location Permission -------------------
if not st.session_state.location_granted:
    show_location_request_screen()
    st.stop()  # Stop execution until location is granted

# ------------------- Main App (Only loads after location permission) -------------------

# Now we have location, continue with the rest of your app
lat = st.session_state.user_lat
lon = st.session_state.user_lon
city = st.session_state.user_city

st.markdown('<h1 class="main-title">üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§π‡§ø‡§§)</h1>', unsafe_allow_html=True)

# ------------------- Enhanced utility functions -------------------
def get_default_soil_data() -> Dict[str, float]:
    """Return default soil data for fallback"""
    return {
        "ph": 6.5,
        "nitrogen": 50,
        "organic_carbon": 10,
        "sand": 40,
        "silt": 40,
        "clay": 20
    }

def get_default_weather_data() -> Dict[str, Any]:
    """Return default weather data for fallback"""
    return {
        "temperature": 25,
        "humidity": 70,
        "precipitation": 2,
        "wind_speed": 10,
        "condition": "‡§∏‡§æ‡§´‡§º"
    }

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_soil(lat: float, lon: float) -> Dict[str, float]:
    """Fetch soil data with better error handling and realistic defaults"""
    try:
        url = "https://rest.isric.org/soilgrids/v2.0/properties"
        params = {
            "lon": lon,
            "lat": lat,
            "property": "phh2o",
            "depth": "0-5cm",
            "value": "mean"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            base_soil = get_default_soil_data()
            lat_factor = (lat - 20) / 20
            base_soil["ph"] += lat_factor * 0.5
            base_soil["nitrogen"] += lat_factor * 10
            return base_soil
            
    except Exception as e:
        logger.error(f"Unexpected error in soil data fetch: {e}")
    
    return get_default_soil_data()

@st.cache_data(ttl=600, show_spinner=False)
def fetch_weather(lat: float, lon: float) -> Dict[str, Any]:
    """Fetch weather data with comprehensive error handling"""
    if not WEATHER_API_KEY:
        return get_default_weather_data()
        
    try:
        url = "http://api.weatherapi.com/v1/current.json"
        params = {
            "key": WEATHER_API_KEY,
            "q": f"{lat},{lon}",
            "aqi": "no"
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            current = data.get("current", {})
            
            return {
                "temperature": current.get("temp_c", 25),
                "humidity": current.get("humidity", 70),
                "precipitation": current.get("precip_mm", 2),
                "wind_speed": current.get("wind_kph", 10),
                "condition": current.get("condition", {}).get("text", "‡§∏‡§æ‡§´‡§º"),
                "feels_like": current.get("feelslike_c", 25),
                "uv": current.get("uv", 5)
            }
            
    except Exception as e:
        logger.error(f"Unexpected error in weather data fetch: {e}")
    
    return get_default_weather_data()

# ------------------- Enhanced ML model -------------------
@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    """Create and train enhanced ML model"""
    np.random.seed(42)
    n_samples = 2000
    
    features = []
    labels = []
    
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        
        features.append([temp, humidity, ph, nitrogen])
        
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)  # ‡§ó‡•á‡§π‡•Ç‡§Å
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)  # ‡§ß‡§æ‡§®
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)  # ‡§Æ‡§ï‡•ç‡§ï‡§æ
        else:
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    clf = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    clf.fit(X_scaled, y)
    
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    """Get crop prediction with confidence score"""
    try:
        clf, scaler = get_trained_model()
        
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        
        crop_map = {0: "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1: "üå± ‡§ß‡§æ‡§®", 2: "üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
        confidence = float(max(probabilities) * 100)
        
        return crop_map.get(prediction, "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§"), confidence
        
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 75.0

# Enhanced initialization with better UX
def perform_comprehensive_warmup():
    """Perform comprehensive system warmup with progress tracking"""
    if st.session_state.app_initialized:
        return True
    
    progress_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        warmup_steps = [
            ("üîß ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠...", 20),
            ("üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§§‡•à‡§Ø‡§æ‡§∞...", 50),
            ("üîä TTS ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§µ‡§æ‡§∞‡•ç‡§Æ ‡§Ö‡§™...", 70),
            ("üìä ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§°...", 90),
            ("‚úÖ ‡§§‡•à‡§Ø‡§æ‡§∞!", 100)
        ]
        
        for step_text, progress_value in warmup_steps:
            status_text.markdown(f'<div class="status-info">{step_text}</div>', unsafe_allow_html=True)
            progress_bar.progress(progress_value)
            time.sleep(0.3)
        
        time.sleep(0.5)
        progress_container.empty()
    
    st.session_state.app_initialized = True
    return True

perform_comprehensive_warmup()

# ------------------- Load environmental data -------------------
with st.spinner("üåç ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§° ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
    soil_data = fetch_soil(lat, lon)
    weather_data = fetch_weather(lat, lon)


# ------------------- Enhanced ML model -------------------
@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    """Create and train enhanced ML model"""
    np.random.seed(42)
    n_samples = 2000  # More training data
    
    features = []
    labels = []
    
    # Generate more diverse and realistic training data
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        
        features.append([temp, humidity, ph, nitrogen])
        
        # Enhanced decision logic for crop recommendation
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)  # ‡§ó‡•á‡§π‡•Ç‡§Å
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)  # ‡§ß‡§æ‡§®
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)  # ‡§Æ‡§ï‡•ç‡§ï‡§æ
        else:
            # Random assignment for edge cases
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    
    # Feature scaling
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train model with better parameters
    clf = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    clf.fit(X_scaled, y)
    
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    """Get crop prediction with confidence score"""
    try:
        clf, scaler = get_trained_model()
        
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        
        crop_map = {0: "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1: "üå± ‡§ß‡§æ‡§®", 2: "üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
        confidence = float(max(probabilities) * 100)
        
        return crop_map.get(prediction, "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§"), confidence
        
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 75.0



# ------------------- Enhanced Sidebar -------------------
with st.sidebar:
    st.header("üéõÔ∏è ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§™‡•à‡§®‡§≤")
    
    # Settings
    st.subheader("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏")
    st.session_state.voice_enabled = st.checkbox("üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡•ç‡§≤‡•á‡§¨‡•à‡§ï", value=st.session_state.voice_enabled)
    st.session_state.auto_play_response = st.checkbox("üéµ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§™‡•ç‡§≤‡•á‡§¨‡•à‡§ï", value=st.session_state.auto_play_response)
    
    response_length = st.selectbox(
        "‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•Ä ‡§≤‡§Ç‡§¨‡§æ‡§à",
        ["‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§", "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø", "‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§"],
        index=1
    )
    
    # Reset button with confirmation
    if st.button("‚ôªÔ∏è ‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", type="secondary"):
        if st.session_state.chat_history:
            st.session_state.chat_history = []
            st.success("‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§π‡•ã ‡§ó‡§à!")
            time.sleep(1)
            st.rerun()
        else:
            st.info("‡§ï‡•ã‡§à ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à")

    # Environmental data display
    st.header("üìä ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§°‡•á‡§ü‡§æ")
    st.success(f"üìç ‡§∏‡•ç‡§•‡§æ‡§®: {city}")

    with st.expander("üå± ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("pH ‡§∏‡•ç‡§§‡§∞", f"{soil_data.get('ph', 0):.1f}", 
                     delta=f"{soil_data.get('ph', 0) - 7.0:.1f} ‡§∏‡•á ‡§®‡•ç‡§Ø‡•Ç‡§ü‡•ç‡§∞‡§≤")
            st.metric("‡§∞‡•á‡§§ %", f"{soil_data.get('sand', 0):.0f}")
            st.metric("‡§ó‡§æ‡§¶ %", f"{soil_data.get('silt', 0):.0f}")
        with col2:
            st.metric("‡§®‡§æ‡§á‡§ü‡•ç‡§∞‡•ã‡§ú‡§®", f"{soil_data.get('nitrogen', 0):.0f}")
            st.metric("‡§ï‡§æ‡§∞‡•ç‡§¨‡§® %", f"{soil_data.get('organic_carbon', 0):.1f}")
            st.metric("‡§ö‡§ø‡§ï‡§®‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä %", f"{soil_data.get('clay', 0):.0f}")

    with st.expander("üå§Ô∏è ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("‡§§‡§æ‡§™‡§Æ‡§æ‡§®", f"{weather_data.get('temperature', 0):.1f}¬∞C")
            st.metric("‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§π‡•ã‡§§‡§æ ‡§π‡•à", f"{weather_data.get('feels_like', weather_data.get('temperature', 25)):.1f}¬∞C")
            st.metric("‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ", f"{weather_data.get('humidity', 0):.0f}%")
        with col2:
            st.metric("‡§¨‡§æ‡§∞‡§ø‡§∂", f"{weather_data.get('precipitation', 0):.1f}mm")
            st.metric("‡§π‡§µ‡§æ ‡§ï‡•Ä ‡§ó‡§§‡§ø", f"{weather_data.get('wind_speed', 0):.1f}km/h")
            if "uv" in weather_data:
                st.metric("UV ‡§∏‡•Ç‡§ö‡§ï‡§æ‡§Ç‡§ï", f"{weather_data.get('uv', 0):.0f}")
        
        st.info(f"‡§Æ‡•å‡§∏‡§Æ: {weather_data.get('condition', '‡§∏‡§æ‡§´‡§º')}")

    # Crop prediction
    predicted_crop, confidence = get_crop_prediction(soil_data, weather_data)
    st.success(f"üéØ ‡§∏‡•Å‡§ù‡§æ‡§à ‡§ó‡§à ‡§´‡§∏‡§≤: {predicted_crop}")
    
    # Enhanced confidence display
    confidence_color = "green" if confidence > 80 else "orange" if confidence > 60 else "red"
    st.markdown(f"‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∏‡•ç‡§§‡§∞: :{confidence_color}[{confidence:.1f}%]")

# ------------------- Enhanced Groq LLM setup -------------------

# ------------------- Voice Input Section -------------------

st.markdown("""
<style>
.chat-container {
    background-color: #000000;  
    color: #FFFFFF;           
    padding: 20px;
    border-radius: 15px;
    box-shadow: 0px 4px 10px rgba(0,0,0,0.5);
    margin-top: 20px;
    margin-bottom: 20px;
    font-family: 'Segoe UI', sans-serif;
}
.chat-container h4 {
    font-size: 1.8rem;
    margin-bottom: 10px;
    color: #00FF7F;
}
.chat-container ul li {
    margin-bottom: 5px;
}
.chat-container em {
    color: #FFD700;
}
</style>

<div class="chat-container">
    <h4>üëã ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡§æ‡§à!</h4>
    <p>‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:</p>
    <ul>
        <li>üåæ <strong>‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂</strong> - ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§´‡§∏‡§≤ ‡§¨‡•ã‡§è‡§Ç</li>
        <li>üå± <strong>‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤</strong> - ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á</li>
        <li>üåßÔ∏è <strong>‡§Æ‡•å‡§∏‡§Æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§∏‡§≤‡§æ‡§π</strong> - ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ñ‡•á‡§§‡•Ä</li>
        <li>üêõ <strong>‡§ï‡•Ä‡§ü ‡§î‡§∞ ‡§∞‡•ã‡§ó ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£</strong> - ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®</li>
        <li>üíß <strong>‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®</strong> - ‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§∏‡§π‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ</li>
        <li>üåø <strong>‡§ú‡•à‡§µ‡§ø‡§ï ‡§ñ‡•á‡§§‡•Ä</strong> - ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§§‡§∞‡•Ä‡§ï‡•á</li>
    </ul>
    <p><em>‡§Ü‡§™ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≤‡§ø‡§ñ‡§ï‡§∞ ‡§Ø‡§æ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç!</em></p>
</div>
""", unsafe_allow_html=True)
st.subheader("üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç")
st.caption("‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•Ä ‡§´‡§º‡§æ‡§á‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (WAV/MP3)")

col1, col2, col3 = st.columns([1, 2, 1])


with col1:
    st.markdown("""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px; 
            border-radius: 16px; 
            box-shadow: 0 8px 16px rgba(0,0,0,0.15);
            margin-bottom: 20px;
        ">
            <h3 style="color: white; text-align: center; margin: 0;">
                üåæ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤
            </h3>
        </div>
    """, unsafe_allow_html=True)
    
    # Tabs for different sections
    tab1, tab3 = st.tabs(["üì§ ‡§Ö‡§™‡§≤‡•ã‡§°", "üí° ‡§ü‡§ø‡§™‡•ç‡§∏"])
    
    with tab1:
        st.markdown("""
            <div style="
                background-color: #f8f9fa;
                padding: 15px;
                border-radius: 12px;
                margin-bottom: 15px;
            ">
                <h4 style="color: #0d6efd; margin-bottom: 15px;">üìÅ ‡§´‡§º‡§æ‡§á‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç</h4>
            </div>
        """, unsafe_allow_html=True)
        
        # Audio Upload Section
 
        st.markdown("---")
        
      
    
    with tab3:
          
            
           
                st.markdown("""
                **‚úÖ ‡§ï‡§∞‡•á‡§Ç:**
                - üì± ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§∞‡§π‡•á‡§Ç (15-20 cm)
                - üîá ‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π ‡§ö‡•Å‡§®‡•á‡§Ç
                - üó£Ô∏è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§î‡§∞ ‡§ß‡•Ä‡§∞‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç
                - ‚è∏Ô∏è ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§õ‡•ã‡§ü‡§æ pause ‡§¶‡•á‡§Ç
                """)
            
           
                st.markdown("""
                **‚ùå ‡§® ‡§ï‡§∞‡•á‡§Ç:**
                - üö´ ‡§§‡•á‡§ú ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç ‡§® ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ‡§è‡§Ç
                - üö´ ‡§¨‡§π‡•Å‡§§ ‡§§‡•á‡§ú ‡§Ø‡§æ ‡§¨‡§π‡•Å‡§§ ‡§ß‡•Ä‡§∞‡•á ‡§® ‡§¨‡•ã‡§≤‡•á‡§Ç
                - üö´ ‡§∂‡•ã‡§∞ ‡§µ‡§æ‡§≤‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§® ‡§ï‡§∞‡•á‡§Ç
                - üö´ ‡§Æ‡§æ‡§á‡§ï ‡§ï‡•ã ‡§π‡§æ‡§• ‡§∏‡•á ‡§® ‡§¢‡§ï‡•á‡§Ç
                """)
        
        # Call Agent Button
   
with col2:
    components.html(
    """
   <elevenlabs-convai agent-id="agent_9301k6w0hb3bf1zbf0pjd1wqwhex"></elevenlabs-convai>
   <script src="https://unpkg.com/@elevenlabs/convai-widget-embed" async type="text/javascript"></script>
    """,
    height=400,  # ‡§ú‡§∞‡•Ç‡§∞‡§§ ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡•á ‡§π‡•ã
)
    audio_file = st.file_uploader("‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§´‡§º‡§æ‡§á‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç", type=["wav", "mp3"])

if audio_file:
    wav_audio_data = audio_file.read()
    if wav_audio_data != st.session_state.get("last_audio_data"):
        st.session_state["last_audio_data"] = wav_audio_data
        st.audio(wav_audio_data, format="audio/wav" if audio_file.type=="audio/wav" else "audio/mp3")
        
        if not st.session_state.get("processing", False):
            st.session_state.processing = True
            try:
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(wav_audio_data)
                    tmp_file.flush()
                    tmp_path = tmp_file.name
                
                try:
                    # Transcribe using your existing STT
                    voice_text = st.session_state.stt.transcribe(tmp_path, language="hi")
                finally:
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
                
                # Process transcription
                if voice_text and voice_text.strip():
                    st.info(f"üìù **{voice_text}**")
                    
                    # LLM response
                with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                        response = get_llm_response(voice_text)
                    
                
                        
                        # TTS
                if st.session_state.get("voice_enabled", False):
                     with st.spinner("üéß ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                                try:
                                    audio_bytes = st.session_state.tts_system.generate_audio(response)
                                    if audio_bytes:
                                        st.audio(audio_bytes, format="audio/mp3")
                                        st.success("üîä ‡§§‡•à‡§Ø‡§æ‡§∞!")
                                except Exception as tts_error:
                                    logger.warning(f"TTS failed: {tts_error}")
                                    st.info("üí° ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§™‡§¢‡§º‡•á‡§Ç")
                          
                else:
                    st.warning("‚ö†Ô∏è ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§•‡•Ä")
                    
            except Exception as e:
                st.error(f"‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {str(e)}")
                logger.error(f"Voice error: {e}", exc_info=True)
            finally:
                st.session_state.processing = False

# ------------------- Enhanced Text Input Section -------------------
def process_text_input(user_input: str):
    """Process text input using unified LLM function"""
    if st.session_state.processing:
        st.warning("‚è≥ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§è‡§ï ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§ö‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à...")
        return
    
    st.session_state.processing = True
    try:
        # Display user message
        with st.chat_message("user"):
            st.markdown(f"‚úçÔ∏è {user_input}")
        
        # Save to history
   
        # LLM response
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_placeholder.markdown("ü§ñ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç... üß†")
            
            full_response = ""
            try:
                for chunk in chain.stream({
                    "question": user_input,
                    "location": city,
                    "temperature": weather_data.get('temperature', 25),
                    "humidity": weather_data.get('humidity', 70),
                    "soil_ph": soil_data.get('ph', 6.5),
                    "nitrogen": soil_data.get('nitrogen', 50),
                    "crop_suggestion": predicted_crop,
                    "confidence": confidence
                }):
                    full_response += chunk
                    response_placeholder.markdown(f"ü§ñ {full_response}")
                    
            except Exception as e:
                error_msg = f"‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {str(e)}"
                response_placeholder.error(f"‚ùå {error_msg}")
                full_response = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§"
                logger.error(f"LLM generation error: {e}")
        
        st.session_state.chat_history.append({
            "role": "user", 
            "content": user_input, 
            "type": "text",
            "timestamp": datetime.now().isoformat()
        })
    
        # Generate audio - NO THREADING, direct call
        if st.session_state.voice_enabled and full_response:
            with st.spinner("üéß ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
                audio_bytes = st.session_state.tts_system.generate_audio(full_response)

                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                    st.success("üîä ‡§§‡•à‡§Ø‡§æ‡§∞!")
                else:
                    st.info("üí° ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ‡§à ‡§ú‡§æ ‡§∏‡§ï‡•Ä‡•§")

    except Exception as e:
        st.error(f"‚ùå ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {str(e)}")
        logger.error(f"Text processing error: {e}")
    finally:
        st.session_state.processing = False

# Handle chat input
if user_input := st.chat_input("‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    process_text_input(user_input)

# ------------------- Enhanced Footer Section -------------------
st.markdown("---")

# Statistics and utilities
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_chats = len([m for m in st.session_state.chat_history if m["role"] == "user"])
    st.metric("üí¨ ‡§ï‡•Å‡§≤ ‡§∏‡§µ‡§æ‡§≤", total_chats)

with col2:
    voice_chats = len([m for m in st.session_state.chat_history if m.get("type") == "voice"])
    st.metric("üé§ ‡§Ü‡§µ‡§æ‡§ú‡§º‡•Ä ‡§∏‡§µ‡§æ‡§≤", voice_chats)

with col3:
    if st.session_state.chat_history:
        last_chat_time = st.session_state.chat_history[-1].get("timestamp", "")
        if last_chat_time:
            st.metric("‚è∞ ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§µ‡§æ‡§≤", last_chat_time[:19].replace('T', ' '))
    else:
        st.metric("‚è∞ ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§µ‡§æ‡§≤", "‡§ï‡•ã‡§à ‡§®‡§π‡•Ä‡§Ç")

with col4:
    # Export chat functionality
    if st.button("üì• ‡§ö‡•à‡§ü ‡§è‡§ï‡•ç‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç"):
        if st.session_state.chat_history:
            chat_export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "location_info": {
                    "city": city,
                    "coordinates": [lat, lon],
                    "weather": weather_data,
                    "soil": soil_data
                },
                "crop_prediction": {
                    "recommended_crop": predicted_crop,
                    "confidence": confidence
                },
                "chat_history": st.session_state.chat_history,
                "statistics": {
                    "total_messages": len(st.session_state.chat_history),
                    "voice_messages": voice_chats,
                    "text_messages": total_chats - voice_chats
                }
            }
            
            # Create downloadable JSON
            json_str = json.dumps(chat_export_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="üíæ JSON ‡§´‡§º‡§æ‡§á‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
                data=json_str,
                file_name=f"agriculture_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•ã JSON ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§ï‡§∞‡•á‡§Ç"
            )
        else:
            st.info("‡§ï‡•ã‡§à ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à")

# Quick action buttons
st.markdown("### üöÄ ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®")
col1, col2, col3 = st.columns(3)

quick_questions = [
    "‡§á‡§∏ ‡§Æ‡•å‡§∏‡§Æ ‡§Æ‡•á‡§Ç ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§´‡§∏‡§≤ ‡§¨‡•á‡§π‡§§‡§∞ ‡§π‡•ã‡§ó‡•Ä?",
    "‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§ï‡•à‡§∏‡•á ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç?",
    "‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?"
]

for i, (col, question) in enumerate(zip([col1, col2, col3], quick_questions)):
    with col:
        if st.button(question, key=f"quick_q_{i}"):
            process_text_input(question)

# Help and information section
with st.expander("‚ÑπÔ∏è ‡§Æ‡§¶‡§¶ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä", expanded=False):
    st.markdown("""
    ### üîß ‡§ï‡•à‡§∏‡•á ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç:
    
    **‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è:**
    1. üé§ "‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°" ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    2. ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡•ã‡§≤‡•á‡§Ç
    3. "‡§∏‡•ç‡§ü‡•â‡§™" ‡§¶‡§¨‡§æ‡§ï‡§∞ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•á‡§Ç  
    4. "‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç" ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    
    **‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è:**
    1. ‡§®‡•Ä‡§ö‡•á ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç
    2. Enter ‡§¶‡§¨‡§æ‡§è‡§Ç ‡§Ø‡§æ ‡§≠‡•á‡§ú‡•á‡§Ç ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç
    
    ### üåæ ‡§Æ‡•à‡§Ç ‡§ï‡§ø‡§® ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç:
    - ‡§´‡§∏‡§≤ ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π (‡§Æ‡•å‡§∏‡§Æ ‡§î‡§∞ ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞)
    - ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á
    - ‡§ï‡•Ä‡§ü ‡§î‡§∞ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§∞‡•ã‡§ï‡§•‡§æ‡§Æ
    - ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§æ ‡§∏‡§π‡•Ä ‡§∏‡§Æ‡§Ø ‡§î‡§∞ ‡§§‡§∞‡•Ä‡§ï‡§æ
    - ‡§ñ‡§æ‡§¶ ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä
    - ‡§ú‡•à‡§µ‡§ø‡§ï ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•á ‡§®‡•Å‡§∏‡•ç‡§ñ‡•á
    - ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ
    
    ### ‚ö†Ô∏è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡•Ç‡§ö‡§®‡§æ:
    - ‡§Ø‡§π ‡§è‡§ï AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à ‡§î‡§∞ ‡§¶‡•Ä ‡§ó‡§à ‡§∏‡§≠‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ï‡•á‡§µ‡§≤ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§π‡•à‡§Ç
    - ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•É‡§∑‡§ø ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§≤‡•á‡§Ç
    - ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü ‡§∞‡•á‡§ü ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§≠‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à (‡§ú‡§≤‡•ç‡§¶ ‡§Ü‡§è‡§ó‡•Ä)
    
    ### üõ†Ô∏è ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ:
    - ‡§Ø‡§¶‡§ø ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡§π‡§ö‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§§‡•ã ‡§∂‡§æ‡§Ç‡§§ ‡§ú‡§ó‡§π ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç
    - ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ß‡•Ä‡§Æ‡§æ ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§•‡•ã‡§°‡§º‡§æ ‡§á‡§Ç‡§§‡§ú‡§º‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç
    - ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è "‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç" ‡§¨‡§ü‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
    """)

# Footer with credits and version info
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;'>
    <p>üåæ <strong>AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï(By AgroMind)</strong> - ‡§Ü‡§™‡§ï‡•á ‡§ñ‡•á‡§§ ‡§ï‡§æ ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§Æ‡§ø‡§§‡•ç‡§∞</p>
    <p><small>‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ 2.0 | Powered by Groq AI , SoilGrids & OpenWeatherMap</small></p>
    <p><small>
        ‡§∏‡§≠‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ï‡•á‡§µ‡§≤ ‡§∏‡•Ç‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡§Ç‡•§ 
        ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•É‡§∑‡§ø ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§≤‡•á‡§Ç‡•§
    </small></p>
</div>
""", unsafe_allow_html=True)


